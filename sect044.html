<!DOCTYPE html>
<html lang="fr" xml:lang="fr">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>4.4 Régression linéaire simple | Méthodes quantitatives en sciences sociales : un grand bol d’R</title>
  <meta name="description" content="Ce livre vise à décrire une panoplie de méthodes quantitatives utilisées en sciences sociales avec le logiciel ouvert R. Il a d’ailleurs été écrit intégralement dans R avec rmarkdown. Le contenu est pensé pour être accessible à tous et toutes, même à ceux et celles n’ayant presque aucune base en statistique ou en programmation. Les personnes plus expérimentées y découvriront des sections sur des méthodes plus avancées comme les modèles à effets mixtes, les modèles multiniveaux, les modèles généralisés additifs ainsi que les méthodes factorielles et de classification. Ceux et celles souhaitant migrer progressivement d’un autre logiciel statistique vers R trouveront dans cet ouvrage les éléments pour une transition en douceur. La philosophie de ce livre est de donner toutes les clefs de compréhension et de mise en œuvre des méthodes abordées dans R. La présentation des méthodes est basée sur une approche compréhensive et intuitive plutôt que mathématique, sans pour autant que la rigueur statistique ne soit négligée." />
  <meta name="generator" content="bookdown 0.21 and GitBook 2.6.7" />

  <meta property="og:title" content="4.4 Régression linéaire simple | Méthodes quantitatives en sciences sociales : un grand bol d’R" />
  <meta property="og:type" content="book" />
  <meta property="og:url" content="https://laeq.github.io/LivreStatistique_website/" />
  <meta property="og:image" content="https://laeq.github.io/LivreStatistique_website/images/introduction/ImageCouverture.png" />
  <meta property="og:description" content="Ce livre vise à décrire une panoplie de méthodes quantitatives utilisées en sciences sociales avec le logiciel ouvert R. Il a d’ailleurs été écrit intégralement dans R avec rmarkdown. Le contenu est pensé pour être accessible à tous et toutes, même à ceux et celles n’ayant presque aucune base en statistique ou en programmation. Les personnes plus expérimentées y découvriront des sections sur des méthodes plus avancées comme les modèles à effets mixtes, les modèles multiniveaux, les modèles généralisés additifs ainsi que les méthodes factorielles et de classification. Ceux et celles souhaitant migrer progressivement d’un autre logiciel statistique vers R trouveront dans cet ouvrage les éléments pour une transition en douceur. La philosophie de ce livre est de donner toutes les clefs de compréhension et de mise en œuvre des méthodes abordées dans R. La présentation des méthodes est basée sur une approche compréhensive et intuitive plutôt que mathématique, sans pour autant que la rigueur statistique ne soit négligée." />
  <meta name="github-repo" content="LAEQ/livre_statistique_Phil_Jere" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="4.4 Régression linéaire simple | Méthodes quantitatives en sciences sociales : un grand bol d’R" />
  
  <meta name="twitter:description" content="Ce livre vise à décrire une panoplie de méthodes quantitatives utilisées en sciences sociales avec le logiciel ouvert R. Il a d’ailleurs été écrit intégralement dans R avec rmarkdown. Le contenu est pensé pour être accessible à tous et toutes, même à ceux et celles n’ayant presque aucune base en statistique ou en programmation. Les personnes plus expérimentées y découvriront des sections sur des méthodes plus avancées comme les modèles à effets mixtes, les modèles multiniveaux, les modèles généralisés additifs ainsi que les méthodes factorielles et de classification. Ceux et celles souhaitant migrer progressivement d’un autre logiciel statistique vers R trouveront dans cet ouvrage les éléments pour une transition en douceur. La philosophie de ce livre est de donner toutes les clefs de compréhension et de mise en œuvre des méthodes abordées dans R. La présentation des méthodes est basée sur une approche compréhensive et intuitive plutôt que mathématique, sans pour autant que la rigueur statistique ne soit négligée." />
  <meta name="twitter:image" content="https://laeq.github.io/LivreStatistique_website/images/introduction/ImageCouverture.png" />

<meta name="author" content="Philippe Apparicio et Jérémy Gelb" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="sect043.html"/>
<link rel="next" href="sect045.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>
<script src="libs/htmlwidgets-1.5.3/htmlwidgets.js"></script>
<script src="libs/d3-4.13.0/d3.min.js"></script>
<script src="libs/d3-tip-0.8.1/index.js"></script>
<link href="libs/chorddiag-0.1.2.9000/chorddiag.css" rel="stylesheet" />
<script src="libs/chorddiag-0.1.2.9000/chorddiag.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css/quizlib.min.css" type="text/css" />
<link rel="stylesheet" href="css/style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Méthodes quantitatives en sciences sociales : un grand bol d'R</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Bienvenue</a></li>
<li class="chapter" data-level="" data-path="préface.html"><a href="préface.html"><i class="fa fa-check"></i>Préface</a><ul>
<li class="chapter" data-level="" data-path="sect001.html"><a href="sect001.html"><i class="fa fa-check"></i>Un manuel sous la forme d’une ressource éducative libre</a></li>
<li class="chapter" data-level="" data-path="sect002.html"><a href="sect002.html"><i class="fa fa-check"></i>Un manuel conçu comme un projet collaboratif</a></li>
<li class="chapter" data-level="" data-path="sect003.html"><a href="sect003.html"><i class="fa fa-check"></i>Comment lire ce livre?</a></li>
<li class="chapter" data-level="" data-path="sect003B.html"><a href="sect003B.html"><i class="fa fa-check"></i>Comment utiliser les données du livre pour reproduire les exemples?</a></li>
<li class="chapter" data-level="" data-path="sect004.html"><a href="sect004.html"><i class="fa fa-check"></i>Structure du livre</a></li>
<li class="chapter" data-level="" data-path="sect005.html"><a href="sect005.html"><i class="fa fa-check"></i>Pourquoi faut-il programmer en sciences sociales?</a></li>
<li class="chapter" data-level="" data-path="sect006.html"><a href="sect006.html"><i class="fa fa-check"></i>Remerciements</a></li>
<li class="chapter" data-level="" data-path="sect007.html"><a href="sect007.html"><i class="fa fa-check"></i>Dédicace toute spéciale à Cargo et Ambrée</a></li>
</ul></li>
<li class="chapter" data-level="" data-path="auteurs.html"><a href="auteurs.html"><i class="fa fa-check"></i>À propos des auteurs</a></li>
<li class="part"><span><b>I Découverte de R</b></span></li>
<li class="chapter" data-level="1" data-path="chap01.html"><a href="chap01.html"><i class="fa fa-check"></i><b>1</b> Prise en main de R</a><ul>
<li class="chapter" data-level="1.1" data-path="sect011.html"><a href="sect011.html"><i class="fa fa-check"></i><b>1.1</b> Histoire et philosophie de R</a></li>
<li class="chapter" data-level="1.2" data-path="sect012.html"><a href="sect012.html"><i class="fa fa-check"></i><b>1.2</b> Environnement de travail</a><ul>
<li class="chapter" data-level="1.2.1" data-path="sect012.html"><a href="sect012.html#sect0121"><i class="fa fa-check"></i><b>1.2.1</b> Installation de R</a></li>
<li class="chapter" data-level="1.2.2" data-path="sect012.html"><a href="sect012.html#sect0122"><i class="fa fa-check"></i><b>1.2.2</b> Environnement RStudio</a></li>
<li class="chapter" data-level="1.2.3" data-path="sect012.html"><a href="sect012.html#sect0123"><i class="fa fa-check"></i><b>1.2.3</b> Installation et chargement un <em>package</em></a></li>
<li class="chapter" data-level="1.2.4" data-path="sect012.html"><a href="sect012.html#aide-disponible"><i class="fa fa-check"></i><b>1.2.4</b> Aide disponible</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="sect013.html"><a href="sect013.html"><i class="fa fa-check"></i><b>1.3</b> Bases du langage R</a><ul>
<li class="chapter" data-level="1.3.1" data-path="sect013.html"><a href="sect013.html#sect0131"><i class="fa fa-check"></i><b>1.3.1</b> <em>Hello World</em>!</a></li>
<li class="chapter" data-level="1.3.2" data-path="sect013.html"><a href="sect013.html#sect0132"><i class="fa fa-check"></i><b>1.3.2</b> Objets et expressions</a></li>
<li class="chapter" data-level="1.3.3" data-path="sect013.html"><a href="sect013.html#sect0_133"><i class="fa fa-check"></i><b>1.3.3</b> Fonctions et arguments</a></li>
<li class="chapter" data-level="1.3.4" data-path="sect013.html"><a href="sect013.html#sect0134"><i class="fa fa-check"></i><b>1.3.4</b> Principaux types de données</a></li>
<li class="chapter" data-level="1.3.5" data-path="sect013.html"><a href="sect013.html#sect0135"><i class="fa fa-check"></i><b>1.3.5</b> Opérateurs</a></li>
<li class="chapter" data-level="1.3.6" data-path="sect013.html"><a href="sect013.html#sect0136"><i class="fa fa-check"></i><b>1.3.6</b> Structures de données</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="sect014.html"><a href="sect014.html"><i class="fa fa-check"></i><b>1.4</b> Manipulation de données</a><ul>
<li class="chapter" data-level="1.4.1" data-path="sect014.html"><a href="sect014.html#sect0141"><i class="fa fa-check"></i><b>1.4.1</b> Chargement d’un <em>DataFrame</em> depuis un fichier</a></li>
<li class="chapter" data-level="1.4.2" data-path="sect014.html"><a href="sect014.html#sect0142"><i class="fa fa-check"></i><b>1.4.2</b> Manipulation d’un <em>DataFrame</em></a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="sect016.html"><a href="sect016.html"><i class="fa fa-check"></i><b>1.5</b> Code R bien structuré</a></li>
<li class="chapter" data-level="1.6" data-path="sect017.html"><a href="sect017.html"><i class="fa fa-check"></i><b>1.6</b> Enregistrement des résultats</a></li>
<li class="chapter" data-level="1.7" data-path="sect018.html"><a href="sect018.html"><i class="fa fa-check"></i><b>1.7</b> Session de travail</a></li>
<li class="chapter" data-level="1.8" data-path="sect019.html"><a href="sect019.html"><i class="fa fa-check"></i><b>1.8</b> Conclusion et ressources pertinentes</a></li>
<li class="chapter" data-level="1.9" data-path="sect0110.html"><a href="sect0110.html"><i class="fa fa-check"></i><b>1.9</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="part"><span><b>II Analyses univariées et graphiques dans R</b></span></li>
<li class="chapter" data-level="2" data-path="chap02.html"><a href="chap02.html"><i class="fa fa-check"></i><b>2</b> Statistiques descriptives univariées</a><ul>
<li class="chapter" data-level="2.1" data-path="sect021.html"><a href="sect021.html"><i class="fa fa-check"></i><b>2.1</b> Notion et types de variable</a><ul>
<li class="chapter" data-level="2.1.1" data-path="sect021.html"><a href="sect021.html#sect0211"><i class="fa fa-check"></i><b>2.1.1</b> Notion de variable</a></li>
<li class="chapter" data-level="2.1.2" data-path="sect021.html"><a href="sect021.html#sect0212"><i class="fa fa-check"></i><b>2.1.2</b> Types de variables</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="sect022.html"><a href="sect022.html"><i class="fa fa-check"></i><b>2.2</b> Types de données</a><ul>
<li class="chapter" data-level="2.2.1" data-path="sect022.html"><a href="sect022.html#sect0221"><i class="fa fa-check"></i><b>2.2.1</b> Données secondaires <em>versus</em> données primaires</a></li>
<li class="chapter" data-level="2.2.2" data-path="sect022.html"><a href="sect022.html#sect0222"><i class="fa fa-check"></i><b>2.2.2</b> Données transversales <em>versus</em> données longitudinales</a></li>
<li class="chapter" data-level="2.2.3" data-path="sect022.html"><a href="sect022.html#sect0223"><i class="fa fa-check"></i><b>2.2.3</b> Données spatiales versus données aspatiales</a></li>
<li class="chapter" data-level="2.2.4" data-path="sect022.html"><a href="sect022.html#sect0224"><i class="fa fa-check"></i><b>2.2.4</b> Données individuelles <em>versus</em> données agrégées</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="sect023.html"><a href="sect023.html"><i class="fa fa-check"></i><b>2.3</b> Statistique descriptive et statistique inférentielle</a><ul>
<li class="chapter" data-level="2.3.1" data-path="sect023.html"><a href="sect023.html#sect0231"><i class="fa fa-check"></i><b>2.3.1</b> Population, échantillon et inférence</a></li>
<li class="chapter" data-level="2.3.2" data-path="sect023.html"><a href="sect023.html#sect0232"><i class="fa fa-check"></i><b>2.3.2</b> Deux grandes familles de méthodes statistiques</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="sect024.html"><a href="sect024.html"><i class="fa fa-check"></i><b>2.4</b> Notion de distribution</a><ul>
<li class="chapter" data-level="2.4.1" data-path="sect024.html"><a href="sect024.html#définition-générale"><i class="fa fa-check"></i><b>2.4.1</b> Définition générale</a></li>
<li class="chapter" data-level="2.4.2" data-path="sect024.html"><a href="sect024.html#anatomie-dune-distribution"><i class="fa fa-check"></i><b>2.4.2</b> Anatomie d’une distribution</a></li>
<li class="chapter" data-level="2.4.3" data-path="sect024.html"><a href="sect024.html#principales-distributions"><i class="fa fa-check"></i><b>2.4.3</b> Principales distributions</a></li>
<li class="chapter" data-level="2.4.4" data-path="sect024.html"><a href="sect024.html#conclusion-sur-les-distributions"><i class="fa fa-check"></i><b>2.4.4</b> Conclusion sur les distributions</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="sect025.html"><a href="sect025.html"><i class="fa fa-check"></i><b>2.5</b> Statistiques descriptives sur des variables quantitatives</a><ul>
<li class="chapter" data-level="2.5.1" data-path="sect025.html"><a href="sect025.html#sect0251"><i class="fa fa-check"></i><b>2.5.1</b> Paramètres de tendance centrale</a></li>
<li class="chapter" data-level="2.5.2" data-path="sect025.html"><a href="sect025.html#sect0252"><i class="fa fa-check"></i><b>2.5.2</b> Paramètres de position</a></li>
<li class="chapter" data-level="2.5.3" data-path="sect025.html"><a href="sect025.html#sect0253"><i class="fa fa-check"></i><b>2.5.3</b> Paramètres de dispersion</a></li>
<li class="chapter" data-level="2.5.4" data-path="sect025.html"><a href="sect025.html#sect0254"><i class="fa fa-check"></i><b>2.5.4</b> Paramètres de forme</a></li>
<li class="chapter" data-level="2.5.5" data-path="sect025.html"><a href="sect025.html#sect0255"><i class="fa fa-check"></i><b>2.5.5</b> Transformation des variables</a></li>
<li class="chapter" data-level="2.5.6" data-path="sect025.html"><a href="sect025.html#sect0256"><i class="fa fa-check"></i><b>2.5.6</b> Mise en œuvre dans R</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="sect026.html"><a href="sect026.html"><i class="fa fa-check"></i><b>2.6</b> Statistiques descriptives sur des variables qualitatives et semi-qualitatives</a><ul>
<li class="chapter" data-level="2.6.1" data-path="sect026.html"><a href="sect026.html#sect0261"><i class="fa fa-check"></i><b>2.6.1</b> Fréquences</a></li>
<li class="chapter" data-level="2.6.2" data-path="sect026.html"><a href="sect026.html#sect0262"><i class="fa fa-check"></i><b>2.6.2</b> Mise en œuvre dans R</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="sect027.html"><a href="sect027.html"><i class="fa fa-check"></i><b>2.7</b> Statistiques descriptives pondérées : pour aller plus loin</a></li>
<li class="chapter" data-level="2.8" data-path="sect028.html"><a href="sect028.html"><i class="fa fa-check"></i><b>2.8</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="chap03.html"><a href="chap03.html"><i class="fa fa-check"></i><b>3</b> Magie des graphiques</a><ul>
<li class="chapter" data-level="3.1" data-path="sect031.html"><a href="sect031.html"><i class="fa fa-check"></i><b>3.1</b> Philosophie du ggplot2</a><ul>
<li class="chapter" data-level="3.1.1" data-path="sect031.html"><a href="sect031.html#sect0311"><i class="fa fa-check"></i><b>3.1.1</b> Grammaire</a></li>
<li class="chapter" data-level="3.1.2" data-path="sect031.html"><a href="sect031.html#sect0312"><i class="fa fa-check"></i><b>3.1.2</b> Types de géométries</a></li>
<li class="chapter" data-level="3.1.3" data-path="sect031.html"><a href="sect031.html#sect0313"><i class="fa fa-check"></i><b>3.1.3</b> Habillage</a></li>
<li class="chapter" data-level="3.1.4" data-path="sect031.html"><a href="sect031.html#utilisation-des-thèmes"><i class="fa fa-check"></i><b>3.1.4</b> Utilisation des thèmes</a></li>
<li class="chapter" data-level="3.1.5" data-path="sect031.html"><a href="sect031.html#sect0314"><i class="fa fa-check"></i><b>3.1.5</b> Composition d’une figure avec plusieurs graphiques</a></li>
<li class="chapter" data-level="3.1.6" data-path="sect031.html"><a href="sect031.html#sect0315"><i class="fa fa-check"></i><b>3.1.6</b> Couleur</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="sect032.html"><a href="sect032.html"><i class="fa fa-check"></i><b>3.2</b> Principaux graphiques</a><ul>
<li class="chapter" data-level="3.2.1" data-path="sect032.html"><a href="sect032.html#sect0321"><i class="fa fa-check"></i><b>3.2.1</b> Histogramme</a></li>
<li class="chapter" data-level="3.2.2" data-path="sect032.html"><a href="sect032.html#sect0322"><i class="fa fa-check"></i><b>3.2.2</b> Graphique de densité</a></li>
<li class="chapter" data-level="3.2.3" data-path="sect032.html"><a href="sect032.html#sect0323"><i class="fa fa-check"></i><b>3.2.3</b> Nuage de points</a></li>
<li class="chapter" data-level="3.2.4" data-path="sect032.html"><a href="sect032.html#sect0324"><i class="fa fa-check"></i><b>3.2.4</b> Graphique en ligne</a></li>
<li class="chapter" data-level="3.2.5" data-path="sect032.html"><a href="sect032.html#sect0325"><i class="fa fa-check"></i><b>3.2.5</b> Boîte à moustaches</a></li>
<li class="chapter" data-level="3.2.6" data-path="sect032.html"><a href="sect032.html#sect0326"><i class="fa fa-check"></i><b>3.2.6</b> Graphique en violon</a></li>
<li class="chapter" data-level="3.2.7" data-path="sect032.html"><a href="sect032.html#sect0327"><i class="fa fa-check"></i><b>3.2.7</b> Graphique en barre</a></li>
<li class="chapter" data-level="3.2.8" data-path="sect032.html"><a href="sect032.html#sect0328"><i class="fa fa-check"></i><b>3.2.8</b> Graphique circulaire</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="sect033.html"><a href="sect033.html"><i class="fa fa-check"></i><b>3.3</b> Graphiques spéciaux</a><ul>
<li class="chapter" data-level="3.3.1" data-path="sect033.html"><a href="sect033.html#sect0331"><i class="fa fa-check"></i><b>3.3.1</b> Graphique en radar</a></li>
<li class="chapter" data-level="3.3.2" data-path="sect033.html"><a href="sect033.html#sect0332"><i class="fa fa-check"></i><b>3.3.2</b> Diagramme d’accord</a></li>
<li class="chapter" data-level="3.3.3" data-path="sect033.html"><a href="sect033.html#sect0333"><i class="fa fa-check"></i><b>3.3.3</b> Nuage de mots</a></li>
<li class="chapter" data-level="3.3.4" data-path="sect033.html"><a href="sect033.html#sect0334"><i class="fa fa-check"></i><b>3.3.4</b> Carte proportionnelle</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="sect034.html"><a href="sect034.html"><i class="fa fa-check"></i><b>3.4</b> Cartes</a></li>
<li class="chapter" data-level="3.5" data-path="sect035.html"><a href="sect035.html"><i class="fa fa-check"></i><b>3.5</b> Exportation des graphiques</a></li>
<li class="chapter" data-level="3.6" data-path="sect036.html"><a href="sect036.html"><i class="fa fa-check"></i><b>3.6</b> Conclusion sur les graphiques</a></li>
</ul></li>
<li class="part"><span><b>III Analyses bivariées</b></span></li>
<li class="chapter" data-level="4" data-path="chap04.html"><a href="chap04.html"><i class="fa fa-check"></i><b>4</b> Relation linéaire entre deux variables quantitatives</a><ul>
<li class="chapter" data-level="4.1" data-path="sect041.html"><a href="sect041.html"><i class="fa fa-check"></i><b>4.1</b> Bref retour sur le postulat de la relation linéaire</a></li>
<li class="chapter" data-level="4.2" data-path="sect042.html"><a href="sect042.html"><i class="fa fa-check"></i><b>4.2</b> Covariance</a><ul>
<li class="chapter" data-level="4.2.1" data-path="sect042.html"><a href="sect042.html#sect0421"><i class="fa fa-check"></i><b>4.2.1</b> Formulation</a></li>
<li class="chapter" data-level="4.2.2" data-path="sect042.html"><a href="sect042.html#sect0422"><i class="fa fa-check"></i><b>4.2.2</b> Interprétation</a></li>
</ul></li>
<li class="chapter" data-level="4.3" data-path="sect043.html"><a href="sect043.html"><i class="fa fa-check"></i><b>4.3</b> Corrélation</a><ul>
<li class="chapter" data-level="4.3.1" data-path="sect043.html"><a href="sect043.html#sect0431"><i class="fa fa-check"></i><b>4.3.1</b> Formulation</a></li>
<li class="chapter" data-level="4.3.2" data-path="sect043.html"><a href="sect043.html#sect0432"><i class="fa fa-check"></i><b>4.3.2</b> Interprétation</a></li>
<li class="chapter" data-level="4.3.3" data-path="sect043.html"><a href="sect043.html#sect0433"><i class="fa fa-check"></i><b>4.3.3</b> Corrélations pour des variables anormalement distribuées (coefficient de Spearman, tau de Kendall)</a></li>
<li class="chapter" data-level="4.3.4" data-path="sect043.html"><a href="sect043.html#sect0434"><i class="fa fa-check"></i><b>4.3.4</b> Corrélations robustes (<em>Biweight midcorrelation</em>, <em>Percentage bend correlation</em> et la corrélation <em>pi</em> de Shepherd)</a></li>
<li class="chapter" data-level="4.3.5" data-path="sect043.html"><a href="sect043.html#sect0435"><i class="fa fa-check"></i><b>4.3.5</b> Significativité des coefficients de corrélation</a></li>
<li class="chapter" data-level="4.3.6" data-path="sect043.html"><a href="sect043.html#sect0436"><i class="fa fa-check"></i><b>4.3.6</b> Corrélation partielle</a></li>
<li class="chapter" data-level="4.3.7" data-path="sect043.html"><a href="sect043.html#sect0437"><i class="fa fa-check"></i><b>4.3.7</b> Mise en œuvre dans R</a></li>
<li class="chapter" data-level="4.3.8" data-path="sect043.html"><a href="sect043.html#sect0438"><i class="fa fa-check"></i><b>4.3.8</b> Comment rapporter des valeurs de corrélations?</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="sect044.html"><a href="sect044.html"><i class="fa fa-check"></i><b>4.4</b> Régression linéaire simple</a><ul>
<li class="chapter" data-level="4.4.1" data-path="sect044.html"><a href="sect044.html#sect0441"><i class="fa fa-check"></i><b>4.4.1</b> Principe de base de la régression linéaire simple</a></li>
<li class="chapter" data-level="4.4.2" data-path="sect044.html"><a href="sect044.html#sect0442"><i class="fa fa-check"></i><b>4.4.2</b> Formulation de la droite de régression des moindres carrés ordinaires</a></li>
<li class="chapter" data-level="4.4.3" data-path="sect044.html"><a href="sect044.html#sect0443"><i class="fa fa-check"></i><b>4.4.3</b> Mesure de la qualité d’ajustement du modèle</a></li>
<li class="chapter" data-level="4.4.4" data-path="sect044.html"><a href="sect044.html#sect0444"><i class="fa fa-check"></i><b>4.4.4</b> Mise en œuvre dans R</a></li>
<li class="chapter" data-level="4.4.5" data-path="sect044.html"><a href="sect044.html#sect0445"><i class="fa fa-check"></i><b>4.4.5</b> Comment rapporter une régression linéaire simple</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="sect045.html"><a href="sect045.html"><i class="fa fa-check"></i><b>4.5</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="chap05.html"><a href="chap05.html"><i class="fa fa-check"></i><b>5</b> Relation entre deux variables qualitatives</a><ul>
<li class="chapter" data-level="5.1" data-path="sect051.html"><a href="sect051.html"><i class="fa fa-check"></i><b>5.1</b> Construction de tableau de contingence</a></li>
<li class="chapter" data-level="5.2" data-path="sect052.html"><a href="sect052.html"><i class="fa fa-check"></i><b>5.2</b> Test du khi-deux</a></li>
<li class="chapter" data-level="5.3" data-path="sect053.html"><a href="sect053.html"><i class="fa fa-check"></i><b>5.3</b> Mise en œuvre dans R</a></li>
<li class="chapter" data-level="5.4" data-path="sect054.html"><a href="sect054.html"><i class="fa fa-check"></i><b>5.4</b> Interprétation d’un tableau de contingence</a></li>
<li class="chapter" data-level="5.5" data-path="sect055.html"><a href="sect055.html"><i class="fa fa-check"></i><b>5.5</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="chap06.html"><a href="chap06.html"><i class="fa fa-check"></i><b>6</b> Relation entre une variable qualitative et une variable quantitative</a><ul>
<li class="chapter" data-level="6.1" data-path="sect061.html"><a href="sect061.html"><i class="fa fa-check"></i><b>6.1</b> Relation entre une variable quantitative et une variable qualitative à deux modalités</a><ul>
<li class="chapter" data-level="6.1.1" data-path="sect061.html"><a href="sect061.html#sect0611"><i class="fa fa-check"></i><b>6.1.1</b> Test <em>t</em> et ses différentes variantes</a></li>
<li class="chapter" data-level="6.1.2" data-path="sect061.html"><a href="sect061.html#sect0612"><i class="fa fa-check"></i><b>6.1.2</b> Test non paramétrique de Wilcoxon</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="sect062.html"><a href="sect062.html"><i class="fa fa-check"></i><b>6.2</b> Relation entre une variable quantitative et une variable qualitative à plus de deux modalités</a><ul>
<li class="chapter" data-level="6.2.1" data-path="sect062.html"><a href="sect062.html#sect0621"><i class="fa fa-check"></i><b>6.2.1</b> Analyse de variance</a></li>
<li class="chapter" data-level="6.2.2" data-path="sect062.html"><a href="sect062.html#sect0622"><i class="fa fa-check"></i><b>6.2.2</b> Test non paramétrique de Kruskal-Wallis</a></li>
<li class="chapter" data-level="6.2.3" data-path="sect062.html"><a href="sect062.html#sect0623"><i class="fa fa-check"></i><b>6.2.3</b> Mise en œuvre dans R</a></li>
<li class="chapter" data-level="6.2.4" data-path="sect062.html"><a href="sect062.html#sect0624"><i class="fa fa-check"></i><b>6.2.4</b> Comment rapporter les résultats d’une ANOVA et du test de Kruskal-Wallis</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="sect063.html"><a href="sect063.html"><i class="fa fa-check"></i><b>6.3</b> Conclusion sur la troisième partie</a></li>
<li class="chapter" data-level="6.4" data-path="sect064.html"><a href="sect064.html"><i class="fa fa-check"></i><b>6.4</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="part"><span><b>IV Modèles de régression</b></span></li>
<li class="chapter" data-level="7" data-path="chap07.html"><a href="chap07.html"><i class="fa fa-check"></i><b>7</b> Régression linéaire multiple</a><ul>
<li class="chapter" data-level="7.1" data-path="sect071.html"><a href="sect071.html"><i class="fa fa-check"></i><b>7.1</b> Objectifs de la régression linéaire multiple et construction d’un modèle de régression</a></li>
<li class="chapter" data-level="7.2" data-path="sect072.html"><a href="sect072.html"><i class="fa fa-check"></i><b>7.2</b> Principes de base de la régression linéaire multiple</a><ul>
<li class="chapter" data-level="7.2.1" data-path="sect072.html"><a href="sect072.html#sect0721"><i class="fa fa-check"></i><b>7.2.1</b> Un peu d’équations…</a></li>
<li class="chapter" data-level="7.2.2" data-path="sect072.html"><a href="sect072.html#sect0722"><i class="fa fa-check"></i><b>7.2.2</b> Hypothèses de la régression linéaire multiple</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="sect073.html"><a href="sect073.html"><i class="fa fa-check"></i><b>7.3</b> Évaluation de la qualité d’ajustement du modèle</a><ul>
<li class="chapter" data-level="7.3.1" data-path="sect073.html"><a href="sect073.html#sect0731"><i class="fa fa-check"></i><b>7.3.1</b> Mesures de la qualité d’un modèle</a></li>
<li class="chapter" data-level="7.3.2" data-path="sect073.html"><a href="sect073.html#sect0732"><i class="fa fa-check"></i><b>7.3.2</b> Comparaison des modèles incrémentiels</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="sect074.html"><a href="sect074.html"><i class="fa fa-check"></i><b>7.4</b> Différentes mesures pour les coefficients de régression</a><ul>
<li class="chapter" data-level="7.4.1" data-path="sect074.html"><a href="sect074.html#sect0741"><i class="fa fa-check"></i><b>7.4.1</b> Coefficients de régression : évaluer l’effet des variables indépendantes</a></li>
<li class="chapter" data-level="7.4.2" data-path="sect074.html"><a href="sect074.html#sect0742"><i class="fa fa-check"></i><b>7.4.2</b> Coefficients de régression standardisés : repérer les variables les plus importantes du modèle</a></li>
<li class="chapter" data-level="7.4.3" data-path="sect074.html"><a href="sect074.html#sect0743"><i class="fa fa-check"></i><b>7.4.3</b> Significativité des coefficients de régression : valeurs de <em>t</em> et de <em>p</em></a></li>
<li class="chapter" data-level="7.4.4" data-path="sect074.html"><a href="sect074.html#sect0744"><i class="fa fa-check"></i><b>7.4.4</b> Intervalle de confiance des coefficients</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="sect075.html"><a href="sect075.html"><i class="fa fa-check"></i><b>7.5</b> Introduction de variables explicatives particulières</a><ul>
<li class="chapter" data-level="7.5.1" data-path="sect075.html"><a href="sect075.html#sect0751"><i class="fa fa-check"></i><b>7.5.1</b> Exploration des relations non linéaires</a></li>
<li class="chapter" data-level="7.5.2" data-path="sect075.html"><a href="sect075.html#sect0752"><i class="fa fa-check"></i><b>7.5.2</b> Variable indépendante qualitative dichotomique</a></li>
<li class="chapter" data-level="7.5.3" data-path="sect075.html"><a href="sect075.html#sect0753"><i class="fa fa-check"></i><b>7.5.3</b> Variable indépendante qualitative polytomique</a></li>
<li class="chapter" data-level="7.5.4" data-path="sect075.html"><a href="sect075.html#sect0754"><i class="fa fa-check"></i><b>7.5.4</b> Variables d’interaction</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="sect076.html"><a href="sect076.html"><i class="fa fa-check"></i><b>7.6</b> Diagnostics de la régression</a><ul>
<li class="chapter" data-level="7.6.1" data-path="sect076.html"><a href="sect076.html#sect0761"><i class="fa fa-check"></i><b>7.6.1</b> Nombre d’observations</a></li>
<li class="chapter" data-level="7.6.2" data-path="sect076.html"><a href="sect076.html#sect0762"><i class="fa fa-check"></i><b>7.6.2</b> Normalité des résidus</a></li>
<li class="chapter" data-level="7.6.3" data-path="sect076.html"><a href="sect076.html#sect0763"><i class="fa fa-check"></i><b>7.6.3</b> Linéarité et homoscédasticité des résidus</a></li>
<li class="chapter" data-level="7.6.4" data-path="sect076.html"><a href="sect076.html#sect0764"><i class="fa fa-check"></i><b>7.6.4</b> Absence de multicolinéarité excessive</a></li>
<li class="chapter" data-level="7.6.5" data-path="sect076.html"><a href="sect076.html#sect0766"><i class="fa fa-check"></i><b>7.6.5</b> Absence d’observations aberrantes</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="sect077.html"><a href="sect077.html"><i class="fa fa-check"></i><b>7.7</b> Mise en œuvre dans R</a><ul>
<li class="chapter" data-level="7.7.1" data-path="sect077.html"><a href="sect077.html#sect0771"><i class="fa fa-check"></i><b>7.7.1</b> Fonctions <code>lm</code>, <code>summary()</code> et <code>confint()</code></a></li>
<li class="chapter" data-level="7.7.2" data-path="sect077.html"><a href="sect077.html#sect0772"><i class="fa fa-check"></i><b>7.7.2</b> Comparaison des modèles</a></li>
<li class="chapter" data-level="7.7.3" data-path="sect077.html"><a href="sect077.html#sect0773"><i class="fa fa-check"></i><b>7.7.3</b> Diagnostic sur un modèle</a></li>
<li class="chapter" data-level="7.7.4" data-path="sect077.html"><a href="sect077.html#sect0774"><i class="fa fa-check"></i><b>7.7.4</b> Graphiques pour les effets marginaux</a></li>
</ul></li>
<li class="chapter" data-level="7.8" data-path="sect078.html"><a href="sect078.html"><i class="fa fa-check"></i><b>7.8</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="chap08.html"><a href="chap08.html"><i class="fa fa-check"></i><b>8</b> Régressions linéaires généralisées (GLM)</a><ul>
<li class="chapter" data-level="8.1" data-path="sect081.html"><a href="sect081.html"><i class="fa fa-check"></i><b>8.1</b> Qu’est qu’un modèle GLM?</a><ul>
<li class="chapter" data-level="8.1.1" data-path="sect081.html"><a href="sect081.html#sect0811"><i class="fa fa-check"></i><b>8.1.1</b> Formulation d’un GLM</a></li>
<li class="chapter" data-level="8.1.2" data-path="sect081.html"><a href="sect081.html#sect0812"><i class="fa fa-check"></i><b>8.1.2</b> Autres distributions et rôle de la fonction de lien</a></li>
<li class="chapter" data-level="8.1.3" data-path="sect081.html"><a href="sect081.html#sect0813"><i class="fa fa-check"></i><b>8.1.3</b> Conditions d’application</a></li>
<li class="chapter" data-level="8.1.4" data-path="sect081.html"><a href="sect081.html#sect0814"><i class="fa fa-check"></i><b>8.1.4</b> Résidus et déviance</a></li>
<li class="chapter" data-level="8.1.5" data-path="sect081.html"><a href="sect081.html#sect0815"><i class="fa fa-check"></i><b>8.1.5</b> Vérification l’ajustement</a></li>
<li class="chapter" data-level="8.1.6" data-path="sect081.html"><a href="sect081.html#sect0816"><i class="fa fa-check"></i><b>8.1.6</b> Comparaison de deux modèles GLM</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="sect082.html"><a href="sect082.html"><i class="fa fa-check"></i><b>8.2</b> Modèles GLM pour des variables qualitatives</a><ul>
<li class="chapter" data-level="8.2.1" data-path="sect082.html"><a href="sect082.html#sect0821"><i class="fa fa-check"></i><b>8.2.1</b> Modèle logistique binomial</a></li>
<li class="chapter" data-level="8.2.2" data-path="sect082.html"><a href="sect082.html#sect0822"><i class="fa fa-check"></i><b>8.2.2</b> Modèle probit binomial</a></li>
<li class="chapter" data-level="8.2.3" data-path="sect082.html"><a href="sect082.html#sect0823"><i class="fa fa-check"></i><b>8.2.3</b> Modèle logistique des cotes proportionnelles</a></li>
<li class="chapter" data-level="8.2.4" data-path="sect082.html"><a href="sect082.html#sect0824"><i class="fa fa-check"></i><b>8.2.4</b> Modèle logistique multinomial</a></li>
<li class="chapter" data-level="8.2.5" data-path="sect082.html"><a href="sect082.html#conclusion-sur-les-modèles-pour-des-variables-qualitatives"><i class="fa fa-check"></i><b>8.2.5</b> Conclusion sur les modèles pour des variables qualitatives</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="sect084.html"><a href="sect084.html"><i class="fa fa-check"></i><b>8.3</b> Modèles GLM pour des variables de comptage</a><ul>
<li class="chapter" data-level="8.3.1" data-path="sect084.html"><a href="sect084.html#sect0841"><i class="fa fa-check"></i><b>8.3.1</b> Modèle de Poisson</a></li>
<li class="chapter" data-level="8.3.2" data-path="sect084.html"><a href="sect084.html#sect0842"><i class="fa fa-check"></i><b>8.3.2</b> Modèle binomial négatif</a></li>
<li class="chapter" data-level="8.3.3" data-path="sect084.html"><a href="sect084.html#sect0843"><i class="fa fa-check"></i><b>8.3.3</b> Modèle de Poisson avec excès fixe de zéros</a></li>
<li class="chapter" data-level="8.3.4" data-path="sect084.html"><a href="sect084.html#sect0844"><i class="fa fa-check"></i><b>8.3.4</b> Modèle de Poisson avec excès ajusté de zéros</a></li>
<li class="chapter" data-level="8.3.5" data-path="sect084.html"><a href="sect084.html#sect0845"><i class="fa fa-check"></i><b>8.3.5</b> Conclusion sur les modèles destinés à des variables de comptage</a></li>
</ul></li>
<li class="chapter" data-level="8.4" data-path="sect085.html"><a href="sect085.html"><i class="fa fa-check"></i><b>8.4</b> Modèles GLM pour des variables continues</a><ul>
<li class="chapter" data-level="8.4.1" data-path="sect085.html"><a href="sect085.html#sect0851"><i class="fa fa-check"></i><b>8.4.1</b> Modèle GLM gaussien</a></li>
<li class="chapter" data-level="8.4.2" data-path="sect085.html"><a href="sect085.html#sect0852"><i class="fa fa-check"></i><b>8.4.2</b> Modèle GLM avec une distribution de Student</a></li>
<li class="chapter" data-level="8.4.3" data-path="sect085.html"><a href="sect085.html#sect0853"><i class="fa fa-check"></i><b>8.4.3</b> Modèle GLM avec distribution Gamma</a></li>
<li class="chapter" data-level="8.4.4" data-path="sect085.html"><a href="sect085.html#sect0854"><i class="fa fa-check"></i><b>8.4.4</b> Modèle GLM avec une distribution bêta</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="sect086.html"><a href="sect086.html"><i class="fa fa-check"></i><b>8.5</b> Conclusion sur les modèles linéaires généralisés</a></li>
<li class="chapter" data-level="8.6" data-path="sect087.html"><a href="sect087.html"><i class="fa fa-check"></i><b>8.6</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="chap09.html"><a href="chap09.html"><i class="fa fa-check"></i><b>9</b> Régressions à effets mixtes (GLMM)</a><ul>
<li class="chapter" data-level="9.1" data-path="sect091.html"><a href="sect091.html"><i class="fa fa-check"></i><b>9.1</b> Introduction</a><ul>
<li class="chapter" data-level="9.1.1" data-path="sect091.html"><a href="sect091.html#sect0911"><i class="fa fa-check"></i><b>9.1.1</b> Indépendance des observations et effets de groupes</a></li>
<li class="chapter" data-level="9.1.2" data-path="sect091.html"><a href="sect091.html#sect0912"><i class="fa fa-check"></i><b>9.1.2</b> Terminologie: effets fixes et effets aléatoires</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="sect092.html"><a href="sect092.html"><i class="fa fa-check"></i><b>9.2</b> Principes de base des GLMM</a><ul>
<li class="chapter" data-level="9.2.1" data-path="sect092.html"><a href="sect092.html#sect0921"><i class="fa fa-check"></i><b>9.2.1</b> GLMM avec constantes aléatoires</a></li>
<li class="chapter" data-level="9.2.2" data-path="sect092.html"><a href="sect092.html#sect0923"><i class="fa fa-check"></i><b>9.2.2</b> GLMM avec pentes aléatoires</a></li>
<li class="chapter" data-level="9.2.3" data-path="sect092.html"><a href="sect092.html#sect0924"><i class="fa fa-check"></i><b>9.2.3</b> GLMM avec constantes et pentes aléatoires</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="sect093.html"><a href="sect093.html"><i class="fa fa-check"></i><b>9.3</b> Conditions d’application des GLMM</a><ul>
<li class="chapter" data-level="9.3.1" data-path="sect093.html"><a href="sect093.html#sect0931"><i class="fa fa-check"></i><b>9.3.1</b> Vérification de la distribution des effets aléatoires</a></li>
<li class="chapter" data-level="9.3.2" data-path="sect093.html"><a href="sect093.html#sect0932"><i class="fa fa-check"></i><b>9.3.2</b> Homogénéité des variances au sein des groupes</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="sect094.html"><a href="sect094.html"><i class="fa fa-check"></i><b>9.4</b> Inférence dans les modèles GLMM</a><ul>
<li class="chapter" data-level="9.4.1" data-path="sect094.html"><a href="sect094.html#sect0941"><i class="fa fa-check"></i><b>9.4.1</b> Inférence pour les effets fixes</a></li>
<li class="chapter" data-level="9.4.2" data-path="sect094.html"><a href="sect094.html#sect0942"><i class="fa fa-check"></i><b>9.4.2</b> Inférence pour les effets aléatoires, effet global</a></li>
<li class="chapter" data-level="9.4.3" data-path="sect094.html"><a href="sect094.html#sect0943"><i class="fa fa-check"></i><b>9.4.3</b> Inférence pour les effets aléatoires, des constantes et des pentes</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="sect095.html"><a href="sect095.html"><i class="fa fa-check"></i><b>9.5</b> Conclusion sur les GLMM</a></li>
<li class="chapter" data-level="9.6" data-path="sect096.html"><a href="sect096.html"><i class="fa fa-check"></i><b>9.6</b> Mise en œuvre des GLMM dans R</a><ul>
<li class="chapter" data-level="9.6.1" data-path="sect096.html"><a href="sect096.html#sect0961"><i class="fa fa-check"></i><b>9.6.1</b> Ajustement du modèle avec uniquement une constante aléatoire</a></li>
<li class="chapter" data-level="9.6.2" data-path="sect096.html"><a href="sect096.html#sect0962"><i class="fa fa-check"></i><b>9.6.2</b> Ajustement du modèle avec constantes et pentes aléatoires</a></li>
</ul></li>
<li class="chapter" data-level="9.7" data-path="sect097.html"><a href="sect097.html"><i class="fa fa-check"></i><b>9.7</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chap10.html"><a href="chap10.html"><i class="fa fa-check"></i><b>10</b> Régressions multiniveaux</a><ul>
<li class="chapter" data-level="10.1" data-path="sect101.html"><a href="sect101.html"><i class="fa fa-check"></i><b>10.1</b> Modèles multiniveaux : deux intérêts majeurs</a><ul>
<li class="chapter" data-level="10.1.1" data-path="sect101.html"><a href="sect101.html#sect1011"><i class="fa fa-check"></i><b>10.1.1</b> Répartition de la variance entre les différents niveaux</a></li>
<li class="chapter" data-level="10.1.2" data-path="sect101.html"><a href="sect101.html#sect1012"><i class="fa fa-check"></i><b>10.1.2</b> Estimation des coefficients aux différents niveaux</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="sect102.html"><a href="sect102.html"><i class="fa fa-check"></i><b>10.2</b> Différents types de modèles multiniveaux</a><ul>
<li class="chapter" data-level="10.2.1" data-path="sect102.html"><a href="sect102.html#sect1021"><i class="fa fa-check"></i><b>10.2.1</b> Description du jeu de données utilisé</a></li>
<li class="chapter" data-level="10.2.2" data-path="sect102.html"><a href="sect102.html#sect1022"><i class="fa fa-check"></i><b>10.2.2</b> Démarche classique pour les modèles multiniveaux</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="sect103.html"><a href="sect103.html"><i class="fa fa-check"></i><b>10.3</b> Conditions d’application des régressions multiniveaux</a></li>
<li class="chapter" data-level="10.4" data-path="sect104.html"><a href="sect104.html"><i class="fa fa-check"></i><b>10.4</b> Mise en œuvre dans R</a><ul>
<li class="chapter" data-level="10.4.1" data-path="sect104.html"><a href="sect104.html#sect1041"><i class="fa fa-check"></i><b>10.4.1</b> Le modèle vide</a></li>
<li class="chapter" data-level="10.4.2" data-path="sect104.html"><a href="sect104.html#sect1042"><i class="fa fa-check"></i><b>10.4.2</b> Modèle avec les variables indépendantes du niveau 1</a></li>
<li class="chapter" data-level="10.4.3" data-path="sect104.html"><a href="sect104.html#sect1043"><i class="fa fa-check"></i><b>10.4.3</b> Modèle avec les variables indépendantes aux niveaux 1 et 2</a></li>
<li class="chapter" data-level="10.4.4" data-path="sect104.html"><a href="sect104.html#sect10414"><i class="fa fa-check"></i><b>10.4.4</b> Modèle complet avec une interaction</a></li>
<li class="chapter" data-level="10.4.5" data-path="sect104.html"><a href="sect104.html#sect1045"><i class="fa fa-check"></i><b>10.4.5</b> Comparaison des quatre modèles</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="sect105.html"><a href="sect105.html"><i class="fa fa-check"></i><b>10.5</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="chap11.html"><a href="chap11.html"><i class="fa fa-check"></i><b>11</b> Modèles généralisés additifs</a><ul>
<li class="chapter" data-level="11.1" data-path="sect111.html"><a href="sect111.html"><i class="fa fa-check"></i><b>11.1</b> Introduction</a><ul>
<li class="chapter" data-level="11.1.1" data-path="sect111.html"><a href="sect111.html#sect1111"><i class="fa fa-check"></i><b>11.1.1</b> Non linéarité fonctionnelle</a></li>
<li class="chapter" data-level="11.1.2" data-path="sect111.html"><a href="sect111.html#sect1112"><i class="fa fa-check"></i><b>11.1.2</b> Non linéarité avec des polynomiales</a></li>
<li class="chapter" data-level="11.1.3" data-path="sect111.html"><a href="sect111.html#sect1113"><i class="fa fa-check"></i><b>11.1.3</b> Non linéarité par segments</a></li>
<li class="chapter" data-level="11.1.4" data-path="sect111.html"><a href="sect111.html#sect1114"><i class="fa fa-check"></i><b>11.1.4</b> Non linéarité avec des <em>splines</em></a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="sect112.html"><a href="sect112.html"><i class="fa fa-check"></i><b>11.2</b> <em>Spline</em> de régression et <em>spline</em> de lissage</a></li>
<li class="chapter" data-level="11.3" data-path="sect113.html"><a href="sect113.html"><i class="fa fa-check"></i><b>11.3</b> Interprétation d’une <em>spline</em></a></li>
<li class="chapter" data-level="11.4" data-path="sect114.html"><a href="sect114.html"><i class="fa fa-check"></i><b>11.4</b> Multicolinéarité non linéaire</a></li>
<li class="chapter" data-level="11.5" data-path="sect115.html"><a href="sect115.html"><i class="fa fa-check"></i><b>11.5</b> <em>Splines</em> avancées</a><ul>
<li class="chapter" data-level="11.5.1" data-path="sect115.html"><a href="sect115.html#sect1151"><i class="fa fa-check"></i><b>11.5.1</b> <em>Splines</em> cycliques</a></li>
<li class="chapter" data-level="11.5.2" data-path="sect115.html"><a href="sect115.html#sect1152"><i class="fa fa-check"></i><b>11.5.2</b> Splines par groupe</a></li>
<li class="chapter" data-level="11.5.3" data-path="sect115.html"><a href="sect115.html#sect1153"><i class="fa fa-check"></i><b>11.5.3</b> <em>Splines</em> multivariées et <em>splines</em> d’interaction</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="sect116.html"><a href="sect116.html"><i class="fa fa-check"></i><b>11.6</b> Mise en oeuvre dans R</a></li>
<li class="chapter" data-level="11.7" data-path="sect117.html"><a href="sect117.html"><i class="fa fa-check"></i><b>11.7</b> GAMM</a></li>
<li class="chapter" data-level="11.8" data-path="sect118.html"><a href="sect118.html"><i class="fa fa-check"></i><b>11.8</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="part"><span><b>V Analyses exploratoires multivariées</b></span></li>
<li class="chapter" data-level="12" data-path="chap12.html"><a href="chap12.html"><i class="fa fa-check"></i><b>12</b> Méthodes factorielles</a><ul>
<li class="chapter" data-level="12.1" data-path="sect121.html"><a href="sect121.html"><i class="fa fa-check"></i><b>12.1</b> Aperçu des méthodes factorielles</a><ul>
<li class="chapter" data-level="12.1.1" data-path="sect121.html"><a href="sect121.html#sect1211"><i class="fa fa-check"></i><b>12.1.1</b> Méthodes factorielles et types de données</a></li>
<li class="chapter" data-level="12.1.2" data-path="sect121.html"><a href="sect121.html#sect1212"><i class="fa fa-check"></i><b>12.1.2</b> Bref historique des méthodes factorielles</a></li>
</ul></li>
<li class="chapter" data-level="12.2" data-path="sect122.html"><a href="sect122.html"><i class="fa fa-check"></i><b>12.2</b> Analyses en composantes principales (ACP)</a><ul>
<li class="chapter" data-level="12.2.1" data-path="sect122.html"><a href="sect122.html#sect1221"><i class="fa fa-check"></i><b>12.2.1</b> Recherche d’une simplification</a></li>
<li class="chapter" data-level="12.2.2" data-path="sect122.html"><a href="sect122.html#sect1222"><i class="fa fa-check"></i><b>12.2.2</b> Aides à l’interprétation</a></li>
<li class="chapter" data-level="12.2.3" data-path="sect122.html"><a href="sect122.html#sect1223"><i class="fa fa-check"></i><b>12.2.3</b> Mise en œuvre dans R</a></li>
</ul></li>
<li class="chapter" data-level="12.3" data-path="sect123.html"><a href="sect123.html"><i class="fa fa-check"></i><b>12.3</b> Analyse factorielle des correspondances (AFC)</a><ul>
<li class="chapter" data-level="12.3.1" data-path="sect123.html"><a href="sect123.html#sect1231"><i class="fa fa-check"></i><b>12.3.1</b> Recherche d’une simplification basée sur la distance du khi-deux</a></li>
<li class="chapter" data-level="12.3.2" data-path="sect123.html"><a href="sect123.html#sect1232"><i class="fa fa-check"></i><b>12.3.2</b> Aides à l’interprétation</a></li>
<li class="chapter" data-level="12.3.3" data-path="sect123.html"><a href="sect123.html#sect1233"><i class="fa fa-check"></i><b>12.3.3</b> Mise en œuvre dans R</a></li>
</ul></li>
<li class="chapter" data-level="12.4" data-path="sect124.html"><a href="sect124.html"><i class="fa fa-check"></i><b>12.4</b> Analyse de correspondances multiples (ACM)</a><ul>
<li class="chapter" data-level="12.4.1" data-path="sect124.html"><a href="sect124.html#sect1241"><i class="fa fa-check"></i><b>12.4.1</b> Aides à l’interprétation</a></li>
<li class="chapter" data-level="12.4.2" data-path="sect124.html"><a href="sect124.html#sect1242"><i class="fa fa-check"></i><b>12.4.2</b> Mise en œuvre dans R</a></li>
</ul></li>
<li class="chapter" data-level="12.5" data-path="sect125.html"><a href="sect125.html"><i class="fa fa-check"></i><b>12.5</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="13" data-path="chap13.html"><a href="chap13.html"><i class="fa fa-check"></i><b>13</b> Méthodes de classification non supervisée</a><ul>
<li class="chapter" data-level="13.1" data-path="sect131.html"><a href="sect131.html"><i class="fa fa-check"></i><b>13.1</b> Méthodes de classification : un aperçu</a></li>
<li class="chapter" data-level="13.2" data-path="sect132.html"><a href="sect132.html"><i class="fa fa-check"></i><b>13.2</b> Notions essentielles en classification</a><ul>
<li class="chapter" data-level="13.2.1" data-path="sect132.html"><a href="sect132.html#sect1321"><i class="fa fa-check"></i><b>13.2.1</b> Distance</a></li>
<li class="chapter" data-level="13.2.2" data-path="sect132.html"><a href="sect132.html#sect1322"><i class="fa fa-check"></i><b>13.2.2</b> Inertie</a></li>
</ul></li>
<li class="chapter" data-level="13.3" data-path="sect133.html"><a href="sect133.html"><i class="fa fa-check"></i><b>13.3</b> Classification ascendante hiérarchique</a><ul>
<li class="chapter" data-level="13.3.1" data-path="sect133.html"><a href="sect133.html#sect1331"><i class="fa fa-check"></i><b>13.3.1</b> Fonctionnement de l’algorithme</a></li>
<li class="chapter" data-level="13.3.2" data-path="sect133.html"><a href="sect133.html#sect1332"><i class="fa fa-check"></i><b>13.3.2</b> Choisir le bon nombre de groupes</a></li>
<li class="chapter" data-level="13.3.3" data-path="sect133.html"><a href="sect133.html#sect1333"><i class="fa fa-check"></i><b>13.3.3</b> Limites de la classification ascendante hiérarchique</a></li>
<li class="chapter" data-level="13.3.4" data-path="sect133.html"><a href="sect133.html#sect1334"><i class="fa fa-check"></i><b>13.3.4</b> Mise en oeuvre dans R</a></li>
</ul></li>
<li class="chapter" data-level="13.4" data-path="sect134.html"><a href="sect134.html"><i class="fa fa-check"></i><b>13.4</b> Nuées dynamiques</a><ul>
<li class="chapter" data-level="13.4.1" data-path="sect134.html"><a href="sect134.html#sect1341"><i class="fa fa-check"></i><b>13.4.1</b> <em>K-means</em></a></li>
<li class="chapter" data-level="13.4.2" data-path="sect134.html"><a href="sect134.html#sect1342"><i class="fa fa-check"></i><b>13.4.2</b> K-médianes</a></li>
<li class="chapter" data-level="13.4.3" data-path="sect134.html"><a href="sect134.html#sect1343"><i class="fa fa-check"></i><b>13.4.3</b> K-médoïds</a></li>
<li class="chapter" data-level="13.4.4" data-path="sect134.html"><a href="sect134.html#sect1344"><i class="fa fa-check"></i><b>13.4.4</b> Mise en oeuvre dans R</a></li>
<li class="chapter" data-level="13.4.5" data-path="sect134.html"><a href="sect134.html#sect1346"><i class="fa fa-check"></i><b>13.4.5</b> Extensions en logique floue : <em>c-means</em>, <em>c-medoids</em></a></li>
</ul></li>
<li class="chapter" data-level="13.5" data-path="sect135.html"><a href="sect135.html"><i class="fa fa-check"></i><b>13.5</b> Conclusion sur la cinquième partie</a></li>
<li class="chapter" data-level="13.6" data-path="sect136.html"><a href="sect136.html"><i class="fa fa-check"></i><b>13.6</b> Quiz de révision du chapitre</a></li>
</ul></li>
<li class="chapter" data-level="14" data-path="annexes.html"><a href="annexes.html"><i class="fa fa-check"></i><b>14</b> Annexes</a><ul>
<li class="chapter" data-level="14.1" data-path="annexe1.html"><a href="annexe1.html"><i class="fa fa-check"></i><b>14.1</b> Table des valeurs critiques de khi-deux</a></li>
<li class="chapter" data-level="14.2" data-path="annexe2.html"><a href="annexe2.html"><i class="fa fa-check"></i><b>14.2</b> Table des valeurs critiques de Fisher</a></li>
<li class="chapter" data-level="14.3" data-path="annexe3.html"><a href="annexe3.html"><i class="fa fa-check"></i><b>14.3</b> Table des valeurs critiques de <em>t</em></a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Méthodes quantitatives en sciences sociales : un grand bol d’R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="sect044" class="section level2">
<h2><span class="header-section-number">4.4</span> Régression linéaire simple</h2>
<div class="bloc_objectif">
<p><strong>Comment expliquer et prédire une variable continue en fonction d’une autre variable?</strong> Répondre à cette question relève de la statistique inférentielle. Il s’agit en effet d’établir une équation simple du type <span class="math inline">\(Y = a + bX\)</span> pour expliquer et prédire les valeurs d’une variable dépendante (<em>Y</em>) à partir d’une variable indépendante (<em>X</em>). L’équation de la régression est construite grâce à un jeu de données (un échantillon). À partir de cette équation, il est possible de prédire la valeur attendue de <em>Y</em> pour n’importe quelle valeur de <em>X</em>. Nous appelons cette équation un modèle, car elle cherche à représenter la réalité de façon simplifiée.</p>
<p>La régression linéaire simple relève ainsi de la statistique inférentielle et se distingue ainsi de la <strong>covariance</strong> (section <a href="sect042.html#sect042">4.2</a>) et de la <strong>corrélation</strong> (section <a href="sect043.html#sect043">4.3</a>) qui relèvent quant à eux de la statistique bivariée descriptive et exploratoire.</p>
<p>Par exemple, la régression linéaire simple pourrait être utilisée pour expliquer les notes d’un groupe d’étudiants et d’étudiantes à un examen (variable dépendante <em>Y</em>) en fonction du nombre d’heures consacrées à la révision des notes de cours (variable indépendante <em>X</em>). Une fois l’équation de régression déterminée et si le modèle est efficace, nous pourrons prédire les notes des personnes inscrites au cours la session suivante en fonction du temps qu’ils ou qu’elles prévoient passer à étudier, et ce, avant l’examen.</p>
<p>Formulons un exemple d’application de la régression linéaire simple en études urbaines. Dans le cadre d’une étude sur les îlots de chaleur urbains, la température de surface (variable dépendante) pourrait être expliquée par la proportion de la superficie de l’îlot couverte par de la végétation (variable indépendante). Nous supposons alors que plus cette proportion est importante, plus la température est faible et inversement, soit une relation linéaire négative. Si le modèle est efficace, nous pourrions prédire la température moyenne des îlots d’une autre municipalité pour laquelle nous ne disposons pas d’une carte de température, et repérer ainsi les îlots de chaleur potentiels. Bien entendu, il est peu probable que nous arrivions à prédire efficacement la température moyenne des îlots avec uniquement la couverture végétale comme variable explicative. En effet, bien d’autres caractéristiques de la forme urbaine peuvent influencer ce phénomène comme la densité du bâti, la couleur des toits, les occupations du sol présentes, l’effet des canyons urbains, etc. Il faudrait alors inclure non pas une, mais plusieurs variables explicatives (indépendantes).</p>
<p>Ainsi, nous distinguons la <strong>régression linéaire simple</strong> (une seule variable indépendante) de la <strong>régression linéaire multiple</strong> (plusieurs variables indépendantes); cette dernière est largement abordée au chapitre <a href="chap07.html#chap07">7</a>.</p>
</div>
<p>Dans cette section, nous décrivons succinctement la régression linéaire simple. Concrètement, nous voyons comment déterminer la droite de régression, interpréter ses différents paramètres du modèle et évaluer la qualité d’ajustement du modèle. Nous n’abordons ni les hypothèses liées au modèle de régression linéaire des moindres carrés ordinaires (MCO) ni les conditions d’application. Ces éléments sont expliqués au chapitre <a href="chap07.html#chap07">7</a>, consacré à la régression linéaire multiple.</p>
<div style="page-break-after: always;"></div>
<div class="bloc_attention">
<p><strong>Corrélation, régression simple et causalité : attention aux raccourcis!</strong></p>
<p>Si une variable <em>X</em> explique et prédit efficacement une variable <em>Y</em>, cela ne veut pas dire pour autant qu’<em>X</em> cause <em>Y</em>. Autrement dit, la corrélation, soit le degré d’association entre deux variables, ne signifie pas qu’il existe un lien de causalité entre elles.</p>
<p>Premièrement, la variable explicative (<em>X</em>, indépendante) doit absolument précéder la variable à expliquer (<em>Y</em>, dépendante). Par exemple, l’âge (<em>X</em>) peut influencer le sentiment de sécurité (<em>Y</em>). Mais, le sentiment de sécurité ne peut en aucun cas influencer l’âge. Par conséquent, l’âge ne peut conceptuellement pas être la variable dépendante dans cette relation.</p>
<p>Deuxièmement, bien qu’une variable puisse expliquer efficacement une autre variable, elle peut être un <strong>facteur confondant</strong>. Prenons deux exemples bien connus :</p>
<ul>
<li>Avoir les doigts jaunes est associé au cancer du poumon. Bien entendu, les doigts jaunes ne causent pas le cancer : c’est un facteur confondant puisque fumer augmente les risques du cancer du poumon et jaunit aussi les doigts.</li>
<li>Dans un article intitulé <em>Chocolate Consumption, Cognitive Function, and Nobel Laureates</em>, Messerli <span class="citation">(<a href="#ref-Messerli" role="doc-biblioref">2012</a>)</span> a trouvé une corrélation positive entre la consommation de chocolat par habitant et le nombre de prix Nobel pour dix millions d’habitants pour 23 pays. Ce résultat a d’ailleurs été rapporté par de nombreux médias, sans pour autant que Messerli <span class="citation">(<a href="#ref-Messerli" role="doc-biblioref">2012</a>)</span> et les journalistes concluent à un lien de causalité entre les deux variables :
<ul>
<li>Radio Canada (<a href="https://ici.radio-canada.ca/nouvelle/582457/chocolat-consommateurs-nobels" class="uri">https://ici.radio-canada.ca/nouvelle/582457/chocolat-consommateurs-nobels</a>)</li>
<li>La Presse (<a href="https://www.lapresse.ca/vivre/sante/nutrition/201210/11/01-4582347-etude-plus-un-pays-mange-de-chocolat-plus-il-a-de-prix-nobel.php" class="uri">https://www.lapresse.ca/vivre/sante/nutrition/201210/11/01-4582347-etude-plus-un-pays-mange-de-chocolat-plus-il-a-de-prix-nobel.php</a>)</li>
<li>Le Point (<a href="https://www.lepoint.fr/insolite/le-chocolat-dope-aussi-l-obtention-de-prix-nobel-12-10-2012-1516159_48.php" class="uri">https://www.lepoint.fr/insolite/le-chocolat-dope-aussi-l-obtention-de-prix-nobel-12-10-2012-1516159_48.php</a>).</li>
</ul></li>
</ul>
<p>Les chercheurs et les chercheures savent bien que la consommation de chocolat ne permet pas d’obtenir des résultats intéressants et de les publier dans des revues prestigieuses; c’est plutôt le café ! Plus sérieusement, il est probable que les pays les plus riches investissent davantage dans la recherche et obtiennent ainsi plus de prix Nobel. Dans les pays les plus riches, il est aussi probable que l’on consomme plus de chocolat, considéré comme un produit de luxe dans les pays les plus pauvres.</p>
<p>Pour approfondir le sujet sur la confusion entre corrélation, régression simple et causalité, vous pouvez visionner cette courte vidéo ludique de vulgarisation (<a href="https://www.youtube.com/embed/A-_naeATJ6o" class="uri">https://www.youtube.com/embed/A-_naeATJ6o</a>).</p>
<p>L’association entre deux variables peut aussi être simplement le fruit du hasard. Si nous explorons de très grandes quantités de données (avec un nombre impressionnant d’observations et de variables), soit une démarche relevant du forage ou de la fouille de données (<em>data mining</em> en anglais), le hasard fera que nous risquons d’obtenir des corrélations surprenantes entre certaines variables. Prenons un exemple concret : admettons que nous ayons collecté 100 variables et que nous calculons les corrélations entre chaque paire de variables. Nous obtenons une matrice de corrélation de 100 x 100, à laquelle nous pouvons enlever la diagonale et une moitié de la matrice, ce qui nous laisse un total de 4950 corrélations différentes. Admettons que nous choisissions un seuil de significativité de 5 %, nous devons alors nous attendre à ce que le hasard produise des résultats significatifs dans 5 % des cas. Sur 4950 corrélations, cela signifie qu’environ 247 corrélations seront significatives, et ce, indépendamment de la nature des données. Nous pouvons aisément illustrer ce fait avec la syntaxe suivante :</p>
<div class="sourceCode" id="cb498"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb498-1"><a href="sect044.html#cb498-1"></a><span class="kw">library</span>(<span class="st">&quot;Hmisc&quot;</span>)</span>
<span id="cb498-2"><a href="sect044.html#cb498-2"></a>nbVars &lt;-<span class="st"> </span><span class="dv">100</span> <span class="co"># nous utilisons 100 variables générées aléatoirement pour l&#39;expérience</span></span>
<span id="cb498-3"><a href="sect044.html#cb498-3"></a>nbExperiment &lt;-<span class="st"> </span><span class="dv">1000</span> <span class="co"># nous reproduirons 1000 fois l&#39;expérience avec les 100 variables</span></span>
<span id="cb498-4"><a href="sect044.html#cb498-4"></a><span class="co"># Le nombre de variables significatives par expérience est enregistré dans Results</span></span>
<span id="cb498-5"><a href="sect044.html#cb498-5"></a>Results &lt;-<span class="st"> </span><span class="kw">c</span>()</span>
<span id="cb498-6"><a href="sect044.html#cb498-6"></a><span class="co"># itérons pour chaque expérimentation (1000 fois)</span></span>
<span id="cb498-7"><a href="sect044.html#cb498-7"></a><span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nbExperiment){</span>
<span id="cb498-8"><a href="sect044.html#cb498-8"></a>  Datas &lt;-<span class="st"> </span><span class="kw">list</span>()</span>
<span id="cb498-9"><a href="sect044.html#cb498-9"></a>  <span class="co"># générons 100 variables aléatoires normalement distribuées</span></span>
<span id="cb498-10"><a href="sect044.html#cb498-10"></a>  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>nbVars){</span>
<span id="cb498-11"><a href="sect044.html#cb498-11"></a>    Datas[[j]] &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">150</span>)</span>
<span id="cb498-12"><a href="sect044.html#cb498-12"></a>  }</span>
<span id="cb498-13"><a href="sect044.html#cb498-13"></a>  DF &lt;-<span class="st"> </span><span class="kw">do.call</span>(<span class="st">&quot;cbind&quot;</span>,Datas)</span>
<span id="cb498-14"><a href="sect044.html#cb498-14"></a>  <span class="co"># calculons la matrice de corrélation pour les 100 variables</span></span>
<span id="cb498-15"><a href="sect044.html#cb498-15"></a>  cor_mat &lt;-<span class="st"> </span><span class="kw">rcorr</span>(DF)</span>
<span id="cb498-16"><a href="sect044.html#cb498-16"></a>  <span class="co"># comptons combien de fois les corrélations étaient significatives</span></span>
<span id="cb498-17"><a href="sect044.html#cb498-17"></a>  Sign &lt;-<span class="st"> </span><span class="kw">table</span>(cor_mat<span class="op">$</span>P<span class="op">&lt;</span><span class="fl">0.05</span>)</span>
<span id="cb498-18"><a href="sect044.html#cb498-18"></a>  NbPairs &lt;-<span class="st"> </span>Sign[[<span class="st">&quot;TRUE&quot;</span>]]<span class="op">/</span><span class="dv">2</span></span>
<span id="cb498-19"><a href="sect044.html#cb498-19"></a>  <span class="co"># ajoutons les résultats dans Results</span></span>
<span id="cb498-20"><a href="sect044.html#cb498-20"></a>  Results &lt;-<span class="st"> </span><span class="kw">c</span>(Results,NbPairs)</span>
<span id="cb498-21"><a href="sect044.html#cb498-21"></a>}</span>
<span id="cb498-22"><a href="sect044.html#cb498-22"></a><span class="co"># transformons Results en un DataFrame</span></span>
<span id="cb498-23"><a href="sect044.html#cb498-23"></a>df &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">Values =</span> Results)</span>
<span id="cb498-24"><a href="sect044.html#cb498-24"></a><span class="co"># affichons le résultat</span></span>
<span id="cb498-25"><a href="sect044.html#cb498-25"></a><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(<span class="dt">x =</span> Values)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb498-26"><a href="sect044.html#cb498-26"></a><span class="st">  </span><span class="kw">geom_histogram</span>(<span class="kw">aes</span>(<span class="dt">y =</span>..density..), </span>
<span id="cb498-27"><a href="sect044.html#cb498-27"></a>                 <span class="dt">colour =</span> <span class="st">&quot;black&quot;</span>, </span>
<span id="cb498-28"><a href="sect044.html#cb498-28"></a>                 <span class="dt">fill =</span> <span class="st">&quot;white&quot;</span>) <span class="op">+</span></span>
<span id="cb498-29"><a href="sect044.html#cb498-29"></a><span class="st">  </span><span class="kw">stat_function</span>(<span class="dt">fun =</span> dnorm, <span class="dt">args =</span> <span class="kw">list</span>(<span class="dt">mean =</span> <span class="kw">mean</span>(df<span class="op">$</span>Values), </span>
<span id="cb498-30"><a href="sect044.html#cb498-30"></a>                <span class="dt">sd =</span> <span class="kw">sd</span>(df<span class="op">$</span>Values)),<span class="dt">color=</span><span class="st">&quot;blue&quot;</span>)<span class="op">+</span></span>
<span id="cb498-31"><a href="sect044.html#cb498-31"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">mean</span>(df<span class="op">$</span>Values),<span class="dt">color=</span><span class="st">&quot;red&quot;</span>, <span class="dt">size=</span><span class="fl">1.2</span>)<span class="op">+</span></span>
<span id="cb498-32"><a href="sect044.html#cb498-32"></a><span class="st">  </span><span class="kw">annotate</span>(<span class="st">&quot;text&quot;</span>, <span class="dt">x=</span><span class="dv">0</span>, <span class="dt">y =</span> <span class="fl">0.028</span>, </span>
<span id="cb498-33"><a href="sect044.html#cb498-33"></a>           <span class="dt">label =</span> <span class="kw">paste</span>(<span class="st">&quot;Nombre moyen de corrélations significatives</span><span class="ch">\n</span></span>
<span id="cb498-34"><a href="sect044.html#cb498-34"></a><span class="st">                         sur 1000 réplications : &quot;</span>,</span>
<span id="cb498-35"><a href="sect044.html#cb498-35"></a>                         <span class="kw">round</span>(<span class="kw">mean</span>(df<span class="op">$</span>Values),<span class="dv">0</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>), <span class="dt">hjust=</span><span class="st">&quot;left&quot;</span>)<span class="op">+</span></span>
<span id="cb498-36"><a href="sect044.html#cb498-36"></a><span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;Nombre de corrélations significatives&quot;</span>)<span class="op">+</span></span>
<span id="cb498-37"><a href="sect044.html#cb498-37"></a><span class="st">  </span><span class="kw">ylab</span>(<span class="st">&quot;densité&quot;</span>)</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:replicationhist"></span>
<img src="images/bivariee/replication_hist.PNG" alt="Corrélations significatives obtenues aléatoirement" width="80%"  />
<p class="caption">
Figure 4.11: Corrélations significatives obtenues aléatoirement
</p>
</div>
</div>
<div id="sect0441" class="section level3">
<h3><span class="header-section-number">4.4.1</span> Principe de base de la régression linéaire simple</h3>
<p>La régression linéaire simple vise à déterminer une droite (une fonction linéaire) qui résume le mieux la relation linéaire entre une variable dépendante (<em>Y</em>) et une variable indépendante (<em>X</em>) :

<span class="math display" id="eq:regsimple">\[\begin{equation}
\widehat{y_i} = \beta_{0} + \beta_{1}x_{i}
\tag{4.7}
\end{equation}\]</span>
</p>
<p>avec <span class="math inline">\(\widehat{y_i}\)</span> et <span class="math inline">\(x_{i}\)</span> qui sont respectivement la valeur prédite de la variable dépendante et la valeur de la variable indépendante pour l’observation <span class="math inline">\(i\)</span>. <span class="math inline">\(\beta_{0}\)</span> est la constante (<em>intercept</em> en anglais) et représente la valeur prédite de la variable <em>Y</em> quand <em>X</em> est égale à 0. <span class="math inline">\(\beta_{1}\)</span> est le coefficient de régression pour la variable <em>X</em>, soit la pente de la droite. Ce coefficient nous informe sur la relation entre les deux variables : s’il est positif, la relation est positive; s’il est négatif, la relation est négative; s’il est proche de 0, la relation est nulle (la droite est alors horizontale). Plus la valeur absolue de <span class="math inline">\(\beta_{1}\)</span> est élevée, plus la pente est forte et plus la variable <em>Y</em> varie à chaque changement d’une unité de la variable <em>X</em>.</p>
<p>Considérons un exemple fictif de dix municipalités d’une région métropolitaine pour lesquelles nous disposons de deux variables : le pourcentage de personnes occupées se rendant au travail principalement à vélo et la distance entre chaque municipalité et le centre-ville de la région métropolitaine (tableau <a href="sect044.html#tab:regfictives">4.3</a>).</p>
<table class="kable_wrapper">
<caption>
<span id="tab:regfictives">Tableau 4.3: </span>Données fictives sur l’utilisation du vélo par municipalité
</caption>
<tbody>
<tr>
<td>
<table>
<thead>
<tr>
<th style="text-align:left;">
Municipalité
</th>
<th style="text-align:center;">
Vélo
</th>
<th style="text-align:right;">
KMCV
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:center;">
12,5
</td>
<td style="text-align:right;">
14,135
</td>
</tr>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:center;">
13,5
</td>
<td style="text-align:right;">
10,065
</td>
</tr>
<tr>
<td style="text-align:left;">
C
</td>
<td style="text-align:center;">
15,8
</td>
<td style="text-align:right;">
7,762
</td>
</tr>
<tr>
<td style="text-align:left;">
D
</td>
<td style="text-align:center;">
15,9
</td>
<td style="text-align:right;">
11,239
</td>
</tr>
<tr>
<td style="text-align:left;">
E
</td>
<td style="text-align:center;">
17,6
</td>
<td style="text-align:right;">
7,706
</td>
</tr>
</tbody>
</table>
</td>
<td>
<table>
<thead>
<tr>
<th style="text-align:left;">
Municipalité
</th>
<th style="text-align:center;">
Vélo
</th>
<th style="text-align:right;">
KMCV
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:center;">
18,5
</td>
<td style="text-align:right;">
7,195
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:center;">
21,2
</td>
<td style="text-align:right;">
7,953
</td>
</tr>
<tr>
<td style="text-align:left;">
H
</td>
<td style="text-align:center;">
23,0
</td>
<td style="text-align:right;">
4,293
</td>
</tr>
<tr>
<td style="text-align:left;">
I
</td>
<td style="text-align:center;">
25,3
</td>
<td style="text-align:right;">
5,225
</td>
</tr>
<tr>
<td style="text-align:left;">
J
</td>
<td style="text-align:center;">
30,2
</td>
<td style="text-align:right;">
2,152
</td>
</tr>
</tbody>
</table>
</td>
</tr>
</tbody>
</table>
<p>D’emblée, à la lecture du nuage de points (figure <a href="sect044.html#fig:figreg">4.12</a>), nous décelons une forte relation linéaire négative entre les deux variables : plus la distance entre la municipalité et le centre-ville de la région métropolitaine augmente, plus le pourcentage de cyclistes est faible, ce qui est confirmé par le coefficient de corrélation (<em>r</em> = −0,90). La droite de régression (en rouge à la figure <a href="sect044.html#fig:figreg">4.12</a>) qui résume le mieux la relation entre <code>Vélo</code> (variable dépendante) et <code>KmCV</code> (variable indépendante) s’écrit alors : <strong>Vélo = 30,603 − 1,448 x KmCV</strong>.</p>
<p>La valeur du coefficient de régression (<span class="math inline">\(\beta_{1}\)</span>) est de −1,448. Le signe de ce coefficient décrit une relation négative entre les deux variables. Ainsi, à chaque ajout d’une unité de la distance entre la municipalité et le centre-ville (exprimée en kilomètres), le pourcentage de cyclistes diminue de 1,448. Retenez que l’unité de mesure de la variable dépendante est très importante pour bien interpréter le coefficient de régression. En effet, si la distance au centre-ville n’était pas exprimée en kilomètres, mais plutôt en mètres, <span class="math inline">\(\beta_1\)</span> serait égal à −0,001448. Dans la même optique, l’ajout de 10 km de distance entre une municipalité et le centre-ville fait diminuer le pourcentage de cyclistes de −14,48 points de pourcentage.</p>
<p>Avec, cette équation de régression, il est possible de prédire le pourcentage de cyclistes pour n’importe quelle municipalité de la région métropolitaine. Par exemple, pour des distances de 5, 10 ou 20 kilomètres, les pourcentages de cyclistes seraient de :</p>
<ul>
<li><span class="math inline">\(\widehat{y_i} = \mbox{30,603} + (\mbox{-1,448} \times \mbox{5 km) = 23,363}\)</span></li>
<li><span class="math inline">\(\widehat{y_i} = \mbox{30,603} + (\mbox{-1,448} \times \mbox{10 km) = 8,883}\)</span></li>
<li><span class="math inline">\(\widehat{y_i} = \mbox{30,603} + (\mbox{-1,448} \times \mbox{20 km) = 1,643}\)</span></li>
</ul>
<div class="figure" style="text-align: center"><span id="fig:figreg"></span>
<img src="MethodesQuantitScSocialesBolR_files/figure-html/figreg-1.png" alt="Relation linéaire entre l'utilisation du vélo et la distance au centre-ville" width="65%" />
<p class="caption">
Figure 4.12: Relation linéaire entre l’utilisation du vélo et la distance au centre-ville
</p>
</div>
</div>
<div id="sect0442" class="section level3">
<h3><span class="header-section-number">4.4.2</span> Formulation de la droite de régression des moindres carrés ordinaires</h3>
<p>Reste à savoir comment sont estimés les différents paramètres de l’équation, soit <span class="math inline">\(\beta_0\)</span> et <span class="math inline">\(\beta_1\)</span>. À la figure <a href="sect044.html#fig:figreg2">4.13</a>, les points noirs représentent les valeurs observées (<span class="math inline">\(y_i\)</span>) et les points bleus, les valeurs prédites (<span class="math inline">\(\widehat{y_i}\)</span>) par l’équation du modèle. Les traits noirs verticaux représentent, pour chaque observation <span class="math inline">\(i\)</span>, l’écart entre la valeur observée et la valeur prédite, dénommé résidu (<span class="math inline">\(\epsilon_i\)</span>, prononcez epsilon de <em>i</em> ou plus simplement le résidu pour <em>i</em> ou le terme d’erreur de <em>i</em>). Si un point est au-dessus de la droite de régression, la valeur observée est alors supérieure à la valeur prédite (<span class="math inline">\(y_i &gt; \widehat{y_i}\)</span>) et inversement, si le point est au-dessous de la droite (<span class="math inline">\(y_i &lt; \widehat{y_i}\)</span>). Plus cet écart (<span class="math inline">\(\epsilon_i\)</span>) est important, plus l’observation s’éloigne de la prédiction du modèle et, par extension, moins bon est le modèle. Au tableau <a href="sect044.html#tab:regfictives2">4.4</a>, vous constaterez que la somme des résidus est égale à zéro. La méthode des moindres carrés ordinaires (MCO) vise à minimiser les écarts au carré entre les valeurs observées (<span class="math inline">\(y_i\)</span>) et prédites (<span class="math inline">\(\beta_0+\beta_1 x_i\)</span>, soit <span class="math inline">\(\widehat{y_i}\)</span>) :</p>

<p><span class="math display" id="eq:mco">\[\begin{equation}
min\sum_{i=1}^n{(y_i-(\beta_0+\beta_1 x_i))^2}
\tag{4.8}
\end{equation}\]</span>
</p>
<p>Pour minimiser ces écarts, le coefficient de régression <span class="math inline">\(\beta_1\)</span> représente le rapport entre la covariance entre <em>X</em> et <em>Y</em> et la variance de <em>Y</em> (équation <a href="sect044.html#eq:b1">(4.9)</a>), tandis que la constante <span class="math inline">\(\beta_0\)</span> est la moyenne de la variable <em>Y</em> moins le produit de la moyenne de <em>X</em> et de son coefficient de régression (équation <a href="sect044.html#eq:b0">(4.10)</a>).</p>

<p><span class="math display" id="eq:b1">\[\begin{equation}
\beta_1 = \frac{\sum_{i=1}^n (x_{i}-\bar{x})(y_{i}-\bar{y})}{\sum_{i=1}^n (x_i-\bar{x})^2} = \frac{cov(X,Y)}{var(X)}
\tag{4.9}
\end{equation}\]</span>
</p>

<p><span class="math display" id="eq:b0">\[\begin{equation}
\beta_0 = \widehat{Y}-\beta_1 \widehat{X}
\tag{4.10}
\end{equation}\]</span>
</p>
<div class="figure" style="text-align: center"><span id="fig:figreg2"></span>
<img src="MethodesQuantitScSocialesBolR_files/figure-html/figreg2-1.png" alt="Droite de régression, valeurs observées, prédites et résidus" width="65%" />
<p class="caption">
Figure 4.13: Droite de régression, valeurs observées, prédites et résidus
</p>
</div>
<table>
<caption>
<span id="tab:regfictives2">Tableau 4.4: </span>Valeurs observées, prédites et résidus
</caption>
<thead>
<tr>
<th style="text-align:left;">
Municipalité
</th>
<th style="text-align:center;">
Vélo
</th>
<th style="text-align:right;">
KmCV
</th>
<th style="text-align:right;">
Valeur prédite
</th>
<th style="text-align:right;">
Résidu
</th>
<th style="text-align:right;">
Résidu au carré
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:center;">
12,5
</td>
<td style="text-align:right;">
14,135
</td>
<td style="text-align:right;">
10,138
</td>
<td style="text-align:right;">
2,362
</td>
<td style="text-align:right;">
5,579
</td>
</tr>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:center;">
13,5
</td>
<td style="text-align:right;">
10,065
</td>
<td style="text-align:right;">
16,031
</td>
<td style="text-align:right;">
-2,531
</td>
<td style="text-align:right;">
6,406
</td>
</tr>
<tr>
<td style="text-align:left;">
C
</td>
<td style="text-align:center;">
15,8
</td>
<td style="text-align:right;">
7,762
</td>
<td style="text-align:right;">
19,365
</td>
<td style="text-align:right;">
-3,565
</td>
<td style="text-align:right;">
12,709
</td>
</tr>
<tr>
<td style="text-align:left;">
D
</td>
<td style="text-align:center;">
15,9
</td>
<td style="text-align:right;">
11,239
</td>
<td style="text-align:right;">
14,331
</td>
<td style="text-align:right;">
1,569
</td>
<td style="text-align:right;">
2,462
</td>
</tr>
<tr>
<td style="text-align:left;">
E
</td>
<td style="text-align:center;">
17,6
</td>
<td style="text-align:right;">
7,706
</td>
<td style="text-align:right;">
19,446
</td>
<td style="text-align:right;">
-1,846
</td>
<td style="text-align:right;">
3,408
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:center;">
18,5
</td>
<td style="text-align:right;">
7,195
</td>
<td style="text-align:right;">
20,186
</td>
<td style="text-align:right;">
-1,686
</td>
<td style="text-align:right;">
2,843
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:center;">
21,2
</td>
<td style="text-align:right;">
7,953
</td>
<td style="text-align:right;">
19,089
</td>
<td style="text-align:right;">
2,111
</td>
<td style="text-align:right;">
4,456
</td>
</tr>
<tr>
<td style="text-align:left;">
H
</td>
<td style="text-align:center;">
23,0
</td>
<td style="text-align:right;">
4,293
</td>
<td style="text-align:right;">
24,388
</td>
<td style="text-align:right;">
-1,388
</td>
<td style="text-align:right;">
1,927
</td>
</tr>
<tr>
<td style="text-align:left;">
I
</td>
<td style="text-align:center;">
25,3
</td>
<td style="text-align:right;">
5,225
</td>
<td style="text-align:right;">
23,038
</td>
<td style="text-align:right;">
2,262
</td>
<td style="text-align:right;">
5,117
</td>
</tr>
<tr>
<td style="text-align:left;">
J
</td>
<td style="text-align:center;">
30,2
</td>
<td style="text-align:right;">
2,152
</td>
<td style="text-align:right;">
27,488
</td>
<td style="text-align:right;">
2,712
</td>
<td style="text-align:right;">
7,355
</td>
</tr>
<tr>
<td style="text-align:left;">
Somme
</td>
<td style="text-align:center;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0,000
</td>
<td style="text-align:right;">
52,262
</td>
</tr>
</tbody>
</table>
</div>
<div id="sect0443" class="section level3">
<h3><span class="header-section-number">4.4.3</span> Mesure de la qualité d’ajustement du modèle</h3>
<p>Les trois mesures les plus courantes pour évaluer la qualité d’ajustement d’un modèle de régression linéaire simple sont l’erreur quadratique moyenne (<em>root-mean-square error</em> en anglais, <em>RMSE</em>), le coefficient de détermination (<em>R<sup>2</sup></em>) et la statistique <em>F</em> de Fisher. Pour mieux appréhender le calcul de ces trois mesures, rappelons que l’équation de régression s’écrit :</p>

<p><span class="math display" id="eq:reg2">\[\begin{equation}
y_i = \beta_0 + \beta_1 x_1+ \epsilon_i \Rightarrow Y= \beta_0 + \beta_1 X + \epsilon
\tag{4.11}
\end{equation}\]</span>
</p>
<p>Elle comprend ainsi une partie de <em>Y</em> qui est expliquée par le modèle et une autre partie non expliquée, soit <span class="math inline">\(\epsilon\)</span>, appelée habituellement le terme d’erreur. Ce terme d’erreur pourrait représenter d’autres variables explicatives qui n’ont pas été prises en compte pour prédire la variable indépendante ou une forme de variation aléatoire inexplicable présente lors de la mesure.</p>

<p><span class="math display" id="eq:reg3">\[\begin{equation}
Y  = \underbrace{\beta_0 + \beta_1 X}_{\mbox{partie expliquée par le modèle}}+ \underbrace{\epsilon}_{\mbox{partie non expliquée}}
\tag{4.12}
\end{equation}\]</span>
</p>
<p>Par exemple, pour la municipalité <em>A</em> au tableau <a href="sect044.html#tab:regfictives2">4.4</a>, nous avons : <span class="math inline">\(y_A = \widehat{y}_A - \epsilon_A \Rightarrow \mbox{12,5} = \mbox{10,138}+\mbox{2,362}\)</span>. Souvenez-vous que la variance d’une variable est la somme des écarts à la moyenne, divisée par le nombre d’observations. Par extension, il est alors possible de décomposer la variance de <em>Y</em> comme suit :</p>

<p><span class="math display" id="eq:reg4">\[\begin{equation}
\underbrace{\sum_{i=1}^n (y_{i}-\bar{y})^2}_{\mbox{variance de Y}} = \underbrace{\sum_{i=1}^n (\widehat{y}_i-\bar{y})^2}_{\mbox{var. expliquée}} + \underbrace{\sum_{i=1}^n (y_{i}-\widehat{y})^2}_{\mbox{var. non expliquée}} \Rightarrow 
SCT = SCE + SCR
\tag{4.13}
\end{equation}\]</span>
</p>
<p>avec :</p>
<ul>
<li><em>SCT</em> est la somme des écarts au carré des valeurs observées à la moyenne (<em>total sum of squares</em> en anglais)</li>
<li><em>SCE</em> est la somme des écarts au carré des valeurs prédites à la moyenne (<em>regression sum of squares</em> en anglais)</li>
<li><em>SCR</em> est la somme des carrés des résidus (<em>sum of squared errors</em> en anglais).</li>
</ul>
<p>Autrement dit, la variance totale est égale à la variance expliquée plus la variance non expliquée. Au tableau <a href="sect044.html#tab:computeR">4.5</a>, vous pouvez repérer les valeurs de <em>SCT</em>, <em>SCE</em> et <em>SCR</em> et constater que 279,30 = 227,04 + 52,26 et 27,93 = 22,70 + 5,23.</p>
<table>
<caption>
<span id="tab:computeR">Tableau 4.5: </span>Calcul du coefficient de détermination
</caption>
<thead>
<tr>
<th style="text-align:left;">
Municipalité
</th>
<th style="text-align:right;">
<span class="math inline">\(y_i\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\widehat{y}_i\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\epsilon_i\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\((y_i-\bar{y})^2\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\((\widehat{y}_i-y_i)^2\)</span>
</th>
<th style="text-align:right;">
<span class="math inline">\(\epsilon_i^2\)</span>
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left;">
A
</td>
<td style="text-align:right;">
12,50
</td>
<td style="text-align:right;">
10,14
</td>
<td style="text-align:right;">
2,36
</td>
<td style="text-align:right;">
46,92
</td>
<td style="text-align:right;">
84,86
</td>
<td style="text-align:right;">
5,58
</td>
</tr>
<tr>
<td style="text-align:left;">
B
</td>
<td style="text-align:right;">
13,50
</td>
<td style="text-align:right;">
16,03
</td>
<td style="text-align:right;">
-2,53
</td>
<td style="text-align:right;">
34,22
</td>
<td style="text-align:right;">
11,02
</td>
<td style="text-align:right;">
6,41
</td>
</tr>
<tr>
<td style="text-align:left;">
C
</td>
<td style="text-align:right;">
15,80
</td>
<td style="text-align:right;">
19,37
</td>
<td style="text-align:right;">
-3,57
</td>
<td style="text-align:right;">
12,60
</td>
<td style="text-align:right;">
0,00
</td>
<td style="text-align:right;">
12,71
</td>
</tr>
<tr>
<td style="text-align:left;">
D
</td>
<td style="text-align:right;">
15,90
</td>
<td style="text-align:right;">
14,33
</td>
<td style="text-align:right;">
1,57
</td>
<td style="text-align:right;">
11,90
</td>
<td style="text-align:right;">
25,19
</td>
<td style="text-align:right;">
2,46
</td>
</tr>
<tr>
<td style="text-align:left;">
E
</td>
<td style="text-align:right;">
17,60
</td>
<td style="text-align:right;">
19,45
</td>
<td style="text-align:right;">
-1,85
</td>
<td style="text-align:right;">
3,06
</td>
<td style="text-align:right;">
0,01
</td>
<td style="text-align:right;">
3,41
</td>
</tr>
<tr>
<td style="text-align:left;">
F
</td>
<td style="text-align:right;">
18,50
</td>
<td style="text-align:right;">
20,19
</td>
<td style="text-align:right;">
-1,69
</td>
<td style="text-align:right;">
0,72
</td>
<td style="text-align:right;">
0,70
</td>
<td style="text-align:right;">
2,84
</td>
</tr>
<tr>
<td style="text-align:left;">
G
</td>
<td style="text-align:right;">
21,20
</td>
<td style="text-align:right;">
19,09
</td>
<td style="text-align:right;">
2,11
</td>
<td style="text-align:right;">
3,42
</td>
<td style="text-align:right;">
0,07
</td>
<td style="text-align:right;">
4,46
</td>
</tr>
<tr>
<td style="text-align:left;">
H
</td>
<td style="text-align:right;">
23,00
</td>
<td style="text-align:right;">
24,39
</td>
<td style="text-align:right;">
-1,39
</td>
<td style="text-align:right;">
13,32
</td>
<td style="text-align:right;">
25,38
</td>
<td style="text-align:right;">
1,93
</td>
</tr>
<tr>
<td style="text-align:left;">
I
</td>
<td style="text-align:right;">
25,30
</td>
<td style="text-align:right;">
23,04
</td>
<td style="text-align:right;">
2,26
</td>
<td style="text-align:right;">
35,40
</td>
<td style="text-align:right;">
13,60
</td>
<td style="text-align:right;">
5,12
</td>
</tr>
<tr>
<td style="text-align:left;">
J
</td>
<td style="text-align:right;">
30,20
</td>
<td style="text-align:right;">
27,49
</td>
<td style="text-align:right;">
2,71
</td>
<td style="text-align:right;">
117,72
</td>
<td style="text-align:right;">
66,22
</td>
<td style="text-align:right;">
7,36
</td>
</tr>
<tr>
<td style="text-align:left;">
N
</td>
<td style="text-align:right;">
10,00
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
</td>
</tr>
<tr>
<td style="text-align:left;">
Somme
</td>
<td style="text-align:right;">
193,50
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0,00
</td>
<td style="text-align:right;">
279,30
</td>
<td style="text-align:right;">
227,04
</td>
<td style="text-align:right;">
52,26
</td>
</tr>
<tr>
<td style="text-align:left;">
Moyenne
</td>
<td style="text-align:right;">
19,35
</td>
<td style="text-align:right;">
</td>
<td style="text-align:right;">
0,00
</td>
<td style="text-align:right;">
27,93
</td>
<td style="text-align:right;">
22,70
</td>
<td style="text-align:right;">
5,23
</td>
</tr>
</tbody>
</table>
<p><strong>Calcul de l’erreur quadratique moyenne</strong></p>
<p>La somme des résidus au carré (<em>SCR</em>) divisée par le nombre d’observations représente donc le carré moyen des erreurs (en anglais, <em>mean square error - MSE</em>), soit la variance résiduelle du modèle (52,26 / 10 = 5,23). Plus sa valeur est faible, plus le modèle est efficace pour prédire la variable indépendante. L’erreur quadratique moyenne (en anglais, <em>root-mean-square error - RMSE</em>) est simplement la racine carrée de la somme des résidus au carré divisée par le nombre d’observations (<span class="math inline">\(n\)</span>) :</p>

<p><span class="math display" id="eq:reg5">\[\begin{equation}
RMSE = \sqrt{\frac{\sum_{i=1}^n (y_{i}-\widehat{y})^2}{n}}
\tag{4.14}
\end{equation}\]</span>
</p>
<p>Elle représente ainsi une <strong>mesure absolue des erreurs</strong> qui est exprimée dans l’unité de mesure de la variable dépendante. Dans le cas présent, nous avons : <span class="math inline">\(\sqrt{5,23}=2,29\)</span>. Cela signifie qu’en moyenne, l’écart absolu (ou erreur absolue) entre les valeurs observées et prédites est de 2,29 points de pourcentage. De nouveau, une plus faible valeur de <strong>RMSE</strong> indique un meilleur ajustement du modèle. Mais surtout, le RMSE permet d’évaluer avec quelle précision le modèle prédit la variable dépendante. Il est donc particulièrement important si l’objectif principal du modèle est de prédire des valeurs sur un échantillon d’observations pour lequel la variable dépendante est inconnue.</p>
<p><strong>Calcul du coefficient de détermination</strong></p>
<p>Nous avons largement démontré que la variance totale est égale à la variance expliquée plus la variance non expliquée. La qualité du modèle peut donc être évaluée avec le coefficient de détermination (<em>R<sup>2</sup></em>), soit le rapport entre les variances expliquée et totale :</p>

<p><span class="math display" id="eq:reg6">\[\begin{equation}
R^2 = \frac{SCE}{SCT} \mbox{ avec } R^2 \in \left[0,1\right]
\tag{4.15}
\end{equation}\]</span>
</p>
<p>Comparativement au RMSE qui est une mesure absolue, le coefficient de détermination est une <strong>mesure relative</strong> qui varie de 0 à 1. Il exprime la proportion de la variance de <em>Y</em> qui est expliquée par la variable <em>X</em>; autrement dit, plus sa valeur est élevée, plus <em>X</em> influence/est capable de prédire <em>Y</em>. Dans le cas présent, nous avons : R<sup>2</sup> = 227,04 / 279,3 = 0,8129, ce qui signale que 81,3 % de la variance du pourcentage de cyclistes est expliquée par la distance entre la municipalité et le centre-ville de la région métropolitaine. Tel que signalé dans la section <a href="sect043.html#sect0432">4.3.2</a>, la racine carrée du coefficient de détermination (<em>R<sup>2</sup></em>) est égale au coefficient de corrélation (<span class="math inline">\(r\)</span>) entre les deux variables.</p>
<p><strong>Calcul de la statistique <em>F</em> de Fisher</strong></p>
<p>La statistique <em>F</em> de Fisher permet de vérifier la significativité globale du modèle.</p>

<p><span class="math display" id="eq:reg7">\[\begin{equation}
F = (n-2)\frac{R^2}{1-R^2} = (n-2)\frac{SCE}{SCR}
\tag{4.16}
\end{equation}\]</span>
</p>
<p>L’hypothèse nulle (<em>H<sub>0</sub></em> avec <span class="math inline">\(\beta_1=0\)</span>) est rejetée si la valeur calculée de <em>F</em> est supérieure à la valeur critique de la table <em>F</em> avec <em>1, n-2</em> degrés de liberté et un seuil <span class="math inline">\(\alpha\)</span> (<em>p</em> = 0,05 habituellement) (voir la table des valeurs critiques de <em>F</em>, section <a href="annexe2.html#annexe2">14.2</a>). Notez que nous utilisons rarement la table <em>F</em> puisqu’avec la fonction <code>pf(f obtenu, 1, n-2, lower.tail = FALSE)</code>, nous obtenons obtient directement la valeur de <em>p</em> associée à la valeur de <em>F</em>. Concrètement, si le test <em>F</em> est significatif (avec <em>p</em> &lt; 0,05), plus la valeur de <em>F</em> est élevée, plus le modèle est efficace (et plus le <em>R<sup>2</sup></em> sera également élevé).</p>
<p>Notez que la fonction <code>summary</code> renvoie les résultats du modèle, dont notamment le test <em>F</em> de Fisher.</p>
<div class="sourceCode" id="cb499"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb499-1"><a href="sect044.html#cb499-1"></a><span class="co"># utiliser la fonction summary</span></span>
<span id="cb499-2"><a href="sect044.html#cb499-2"></a><span class="kw">summary</span>(modele)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Velo ~ KmCV, data = data)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.5652 -1.8062  0.0906  2.2241  2.7125 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  30.6032     2.0729  14.763 4.36e-07 ***
## KmCV         -1.4478     0.2456  -5.895 0.000364 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.556 on 8 degrees of freedom
## Multiple R-squared:  0.8129, Adjusted R-squared:  0.7895 
## F-statistic: 34.75 on 1 and 8 DF,  p-value: 0.0003637</code></pre>
<p>Dans le cas présent, <span class="math inline">\(F = (10 - 2)\frac{\mbox{0,8129}}{\mbox{1-0,8129}} = (10-2)\frac{\mbox{227,04}}{\mbox{52,26}} = \mbox{34,75}\)</span> avec une valeur de <span class="math inline">\(\mbox{p &lt; 0,001}\)</span>. Par conséquent, le modèle est significatif.</p>
</div>
<div id="sect0444" class="section level3">
<h3><span class="header-section-number">4.4.4</span> Mise en œuvre dans R</h3>
<p>Comment calculer une régression linéaire simple dans R. Rien de plus simple avec la fonction <code>lm(formula = y ~ x, data= DataFrame)</code>.</p>
<div class="sourceCode" id="cb501"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb501-1"><a href="sect044.html#cb501-1"></a>df1 &lt;-<span class="st"> </span><span class="kw">read.csv</span>(<span class="st">&quot;data/bivariee/Reg.csv&quot;</span>, <span class="dt">stringsAsFactors =</span> F)</span>
<span id="cb501-2"><a href="sect044.html#cb501-2"></a><span class="co">## Création d&#39;un objet pour le modèle</span></span>
<span id="cb501-3"><a href="sect044.html#cb501-3"></a>monmodele &lt;-<span class="st"> </span><span class="kw">lm</span>(Velo <span class="op">~</span><span class="st"> </span>KmCV, df1)</span>
<span id="cb501-4"><a href="sect044.html#cb501-4"></a><span class="co">## Résultats du modèle avec la fonction summary</span></span>
<span id="cb501-5"><a href="sect044.html#cb501-5"></a><span class="kw">summary</span>(monmodele)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = Velo ~ KmCV, data = df1)
## 
## Residuals:
##     Min      1Q  Median      3Q     Max 
## -3.5652 -1.8062  0.0906  2.2241  2.7125 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  30.6032     2.0729  14.763 4.36e-07 ***
## KmCV         -1.4478     0.2456  -5.895 0.000364 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.556 on 8 degrees of freedom
## Multiple R-squared:  0.8129, Adjusted R-squared:  0.7895 
## F-statistic: 34.75 on 1 and 8 DF,  p-value: 0.0003637</code></pre>
<div class="sourceCode" id="cb503"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb503-1"><a href="sect044.html#cb503-1"></a><span class="co">## Calcul du MSE et du RMSE</span></span>
<span id="cb503-2"><a href="sect044.html#cb503-2"></a>MSE &lt;-<span class="st"> </span><span class="kw">mean</span>(monmodele<span class="op">$</span>residuals<span class="op">^</span><span class="dv">2</span>)</span>
<span id="cb503-3"><a href="sect044.html#cb503-3"></a>RMSE &lt;-<span class="st"> </span><span class="kw">sqrt</span>(MSE)</span>
<span id="cb503-4"><a href="sect044.html#cb503-4"></a><span class="kw">cat</span>(<span class="st">&quot;MSE=&quot;</span>, <span class="kw">round</span>(MSE, <span class="dv">2</span>), <span class="st">&quot;; RMSE=&quot;</span>, <span class="kw">round</span>(RMSE,<span class="dv">2</span>), <span class="dt">sep=</span><span class="st">&quot;&quot;</span>)</span></code></pre></div>
<pre><code>## MSE=5.23; RMSE=2.29</code></pre>
</div>
<div id="sect0445" class="section level3">
<h3><span class="header-section-number">4.4.5</span> Comment rapporter une régression linéaire simple</h3>
<p>Nous avons calculé une régression linéaire simple pour prédire le pourcentage d’actifs occupés utilisant le vélo pour se rendre au travail en fonction de la distance entre la municipalité et le centre-ville de la région métropolitaine (en kilomètres). Le modèle obtient un <em>F</em> de Fisher significatif (<em>F</em>(1,8) = 34,75, <em>p</em> &lt; 0,001) et un <em>R<sup>2</sup></em> de 0,813. Le pourcentage de cyclistes peut être prédit par l’équation suivante : 30,603 - 1,448 x (distance au centre-ville en km).</p>
<div style="page-break-after: always;"></div>
</div>
</div>
<h3>R&eacute;f&eacute;rences</h3>
<div id="refs" class="references">
<div id="ref-Messerli">
<p>Messerli, Franz H. 2012. « Chocolate consumption, cognitive Function, and Nobel laureates ». <em>The new England Journal of Medicine</em> 367 (16): 1563‑1564. <a href="https://doi.org/10.1056/nejmon1211064">https://doi.org/10.1056/nejmon1211064</a>.</p>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="sect043.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="sect045.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": true,
"facebook": false,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["MethodesQuantitScSocialesBolR.pdf"],
"toc": {
"collapse": "none"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
